{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "# Apache 라이선스, 버전 2.0(\"라이선스\")에 따라 라이선스가 부여됩니다.\n",
        "# 이 파일은 라이선스를 준수하는 경우에만 사용할 수 있습니다.\n",
        "# 라이선스 전문은 다음에서 확인할 수 있습니다:\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# 관련 법률에 따라 요구되지 않는 한 또는 서면 동의가 없는 한,\n",
        "# 이 소프트웨어는 \"있는 그대로(AS IS)\" 제공되며,\n",
        "# 명시적이든 묵시적이든 어떠한 형태의 보증도 제공하지 않습니다.\n",
        "# 사용 권한과 제한 사항에 대한 자세한 내용은 위의 라이선스를 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# MediaPipe Tasks를 활용한 자세 랜드마크 검출\n",
        "\n",
        "이 노트북에서는 MediaPipe Tasks Python API를 사용하여 이미지에서 자세(포즈) 랜드마크를 검출하는 방법을 소개합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install -q mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "그 다음, 기본 제공되는 모델 번들을 다운로드하세요.  \n",
        "이 모델 번들에 대한 자세한 내용은 [MediaPipe 공식 문서](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker#models)를 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "!wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKAJ5nDU8-I"
      },
      "source": [
        "## 🎨 Visualization Utilities\n",
        "\n",
        "이 섹션은 **시각화 전용 도구 함수**를 정의합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔧 기능\n",
        "\n",
        "- 👉 입력 이미지와 검출 결과(`detection_result`)를 받아  \n",
        "- 👉 이미지 위에 사람의 **랜드마크와 관절 연결선**을 그림  \n",
        "\n",
        "---\n",
        "\n",
        "### 🧰 사용 기술\n",
        "\n",
        "- **MediaPipe 시각화 유틸리티**  \n",
        "  `solutions.drawing_utils.draw_landmarks(...)` 를 사용해 랜드마크를 이미지에 표시합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### ⚠️ 참고\n",
        "\n",
        "- 이 코드는 **아직 실행되는 부분은 없습니다.**\n",
        "- 단순히 `draw_landmarks_on_image()`라는 **헬퍼 함수만 정의**합니다.\n",
        "- 💡 즉, **분석은 하지 않고**, **그리기만 하는 도구**입니다.\n",
        "\n",
        "이 함수는 여러 곳에서 재사용될 수 있도록 분리된 구조로 설계되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3E6NFV-00Qt"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 및 모듈을 가져옵니다.\n",
        "from mediapipe import solutions  # MediaPipe 솔루션 (그리기 유틸리티 등 포함)\n",
        "from mediapipe.framework.formats import landmark_pb2 # 랜드마크 데이터를 위한 프로토콜 버퍼 형식\n",
        "import numpy as np # NumPy 라이브러리 (이미지 배열 처리에 사용)\n",
        "\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  \"\"\"이미지 위에 감지된 포즈 랜드마크와 연결선을 그립니다.\n",
        "\n",
        "  Args:\n",
        "    rgb_image: 랜드마크를 그릴 원본 RGB 이미지 (NumPy 배열).\n",
        "    detection_result: MediaPipe PoseLandmarker의 감지 결과 객체.\n",
        "\n",
        "  Returns:\n",
        "    랜드마크와 연결선이 그려진 이미지 (NumPy 배열).\n",
        "  \"\"\"\n",
        "  # 감지 결과에서 포즈 랜드마크 목록을 가져옵니다.\n",
        "  pose_landmarks_list = detection_result.pose_landmarks\n",
        "  # 원본 이미지를 복사하여 주석(랜드마크)을 추가할 이미지를 만듭니다.\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # 감지된 각 포즈(사람)에 대해 반복합니다.\n",
        "  for idx in range(len(pose_landmarks_list)):\n",
        "    # 현재 인덱스(idx)에 해당하는 포즈 랜드마크를 가져옵니다.\n",
        "    pose_landmarks = pose_landmarks_list[idx]\n",
        "\n",
        "    # 포즈 랜드마크를 그리기 위한 준비: landmark_pb2.NormalizedLandmarkList 형식으로 변환합니다.\n",
        "    # draw_landmarks 함수는 이 형식을 입력으로 받습니다.\n",
        "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    pose_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
        "    ])\n",
        "\n",
        "    # 이미지 위에 포즈 랜드마크와 연결선을 그립니다.\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "      annotated_image, # 랜드마크를 그릴 이미지\n",
        "      pose_landmarks_proto, # 그릴 랜드마크 데이터 (NormalizedLandmarkList 형식)\n",
        "      solutions.pose.POSE_CONNECTIONS, # 랜드마크 간의 연결 정보 (어떤 랜드마크끼리 선으로 이을지 정의)\n",
        "      solutions.drawing_styles.get_default_pose_landmarks_style()) # 랜드마크와 연결선의 기본 스타일 (색상, 두께 등)\n",
        "\n",
        "  # 랜드마크와 연결선이 그려진 이미지를 반환합니다.\n",
        "  return annotated_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## Download test image\n",
        "\n",
        "To demonstrate the Pose Landmarker API, you can download a sample image using the follow code. The image is from [Pixabay](https://pixabay.com/photos/girl-woman-fitness-beautiful-smile-4051811/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [],
      "source": [
        "!wget -q -O image.jpg https://cdn.pixabay.com/photo/2019/03/12/20/39/girl-4051811_960_720.jpg\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"image.jpg\")\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-skLwMBmMN_"
      },
      "source": [
        "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBjSdwImQPw"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for filename in uploaded:\n",
        "#   content = uploaded[filename]\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(content)\n",
        "\n",
        "# if len(uploaded.keys()):\n",
        "#   IMAGE_FILE = next(iter(uploaded))\n",
        "#   print('Uploaded file:', IMAGE_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## 🧠 추론 실행 및 결과 시각화\n",
        "\n",
        "이 단계는 **포즈 랜드마크 추론을 실제로 실행**하고  \n",
        "결과를 **이미지 위에 시각화**하는 전체 파이프라인을 포함합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 🪜 전체 흐름\n",
        "\n",
        "1. **모델 로드**  \n",
        "   `.task` 모델 파일을 메모리에 불러옵니다.\n",
        "   \n",
        "2. **PoseLandmarker 옵션 설정**  \n",
        "   모델 경로, 마스크 출력 여부 등 실행 조건을 정의합니다.\n",
        "   \n",
        "3. **이미지 로드**  \n",
        "   분석할 이미지를 파일에서 불러옵니다.\n",
        "   \n",
        "4. **검출 수행**  \n",
        "   `detector.detect(image)`를 통해 이미지에서 포즈를 인식합니다.\n",
        "   \n",
        "5. **검출 결과 시각화**  \n",
        "   `draw_landmarks_on_image(...)`를 호출하여  \n",
        "   이미지 위에 관절 위치와 연결선을 시각적으로 표시합니다.  \n",
        "   👉 여기서 **이전에 정의한 시각화 함수가 사용됩니다.**\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 핵심 함수 요약\n",
        "\n",
        "| 함수 | 설명 |\n",
        "|------|------|\n",
        "| `detector.detect(image)` | 실제 자세 추정 수행 |\n",
        "| `draw_landmarks_on_image(...)` | 검출 결과를 이미지 위에 시각화 (헬퍼 함수 사용) |\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 참고 링크\n",
        "\n",
        "더 다양한 설정 옵션을 알고 싶다면  \n",
        "👉 [MediaPipe 공식 문서 보기](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JVO3rvPD4RN"
      },
      "outputs": [],
      "source": [
        "# STEP 1: 필요한 모듈 가져오기 (Import the necessary modules.)\n",
        "import mediapipe as mp  # MediaPipe 라이브러리를 mp라는 이름으로 가져옵니다.\n",
        "from mediapipe.tasks import python # MediaPipe Tasks 관련 기본 기능을 가져옵니다.\n",
        "from mediapipe.tasks.python import vision # MediaPipe의 비전 관련 작업(예: 포즈 감지) 기능을 가져옵니다.\n",
        "\n",
        "# STEP 2: PoseLandmarker 객체 생성하기 (Create an PoseLandmarker object.)\n",
        "# 모델 파일 경로 등 기본 옵션을 설정합니다.\n",
        "base_options = python.BaseOptions(model_asset_path='Project/Climbing-Project/pose_landmarker_full.task')\n",
        "\n",
        "# PoseLandmarker에 특화된 옵션을 설정합니다.\n",
        "options = vision.PoseLandmarkerOptions(\n",
        "    base_options=base_options, # 위에서 설정한 기본 옵션을 사용합니다.  / 모델 파일 경로 등\n",
        "    num_poses=2, # 감지할 포즈(사람)의 최대 개수입니다. (최대 2명)\n",
        "    min_detection_confidence=0.5, # 감지 신뢰도 임계값입니다. (0.0 ~ 1.0)\n",
        "    min_tracking_confidence=0.5, # 추적 신뢰도 임계값입니다. (0.0 ~ 1.0)\n",
        "    # 포즈 랜드마크의 세부 정보입니다.\n",
        "    # pose_landmarks_to_return=vision.PoseLandmarkerOptions.PoseLandmarksToReturn.ALL, # 모든 랜드마크를 반환합니다.\n",
        "    pose_landmarks_to_return=vision.PoseLandmarkerOptions.PoseLandmarksToReturn.NOSE_ONLY, # 코 부위 랜드마크만 반환합니다.\n",
        "    # 포즈 랜드마크의 세부 정보입니다.\n",
        "    # output_world_landmarks=True, # 월드 좌표계 랜드마크를 출력합니다.\n",
        "    output_world_landmarks=False, # 월드 좌표계 랜드마크를 출력하지 않습니다.\n",
        "    # output_segmentation_masks=True, # 사람 영역을 분할하는 마스크를 출력합니다.\n",
        "    output_segmentation_masks=True) # 사람 영역을 분할하는 마스크도 출력하도록 설정합니다.\n",
        "\n",
        "# 설정된 옵션들을 사용하여 PoseLandmarker 감지기(detector) 객체를 생성합니다.\n",
        "detector = vision.PoseLandmarker.create_from_options(options)\n",
        "\n",
        "# STEP 3: 입력 이미지 불러오기 (Load the input image.)\n",
        "# \"image.jpg\" 파일로부터 이미지를 로드하여 MediaPipe가 처리할 수 있는 Image 객체로 만듭니다.\n",
        "image = mp.Image.create_from_file(\"image.jpg\")\n",
        "\n",
        "# STEP 4: 입력 이미지에서 포즈 랜드마크 감지하기 (Detect pose landmarks from the input image.)\n",
        "# 생성된 감지기(detector)를 사용하여 로드한 이미지에서 포즈 랜드마크를 감지합니다.\n",
        "detection_result = detector.detect(image)\n",
        "# 감지 결과는 detection_result 객체에 저장됩니다.\n",
        "# 이 객체는 감지된 포즈 랜드마크와 관련된 정보를 포함하고 있습니다.\n",
        "# 감지된 포즈 랜드마크는 detection_result.pose_landmarks 속성으로 접근할 수 있습니다.\n",
        "# detection_result.pose_landmarks는 감지된 포즈 랜드마크의 리스트입니다.\n",
        "# 각 포즈 랜드마크는 x, y, z 좌표를 포함하고 있습니다.\n",
        "# 감지된 포즈 랜드마크는 이미지의 크기와 비율에 따라 정규화된 좌표로 표현됩니다.\n",
        "# 감지된 포즈 랜드마크의 개수와 각 랜드마크의 좌표를 출력합니다.\n",
        "print(f\"Detected {len(detection_result.pose_landmarks)} pose landmarks.\")\n",
        "for idx, pose_landmarks in enumerate(detection_result.pose_landmarks):\n",
        "  print(f\"Pose {idx}:\")\n",
        "  for landmark in pose_landmarks:\n",
        "    print(f\"  x: {landmark.x}, y: {landmark.y}, z: {landmark.z}\")\n",
        "# 감지된 포즈 랜드마크의 개수와 각 랜드마크의 좌표를 출력합니다.\n",
        "# 감지된 포즈 랜드마크의 개수는 detection_result.pose_landmarks의 길이로 확인할 수 있습니다.\n",
        "\n",
        "\n",
        "# STEP 5: 감지 결과 처리하기 (Process the detection result.) 여기서는 시각화를 합니다.\n",
        "# 앞에서 정의한 draw_landmarks_on_image 함수를 사용하여\n",
        "# 원본 이미지(NumPy 배열 형태로 변환) 위에 감지된 랜드마크를 그립니다.\n",
        "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
        "# 랜드마크가 그려진 이미지를 화면에 표시합니다.\n",
        "# (OpenCV는 BGR 색상 순서를 사용하므로 RGB 이미지를 BGR로 변환하여 표시합니다.)\n",
        "# cv2_imshow는 Colab 환경에서 이미지를 표시하는 함수일 수 있습니다.\n",
        "cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BwzFvaxwtPX"
      },
      "source": [
        "Visualize the pose segmentation mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jAIFzw9M3JJ"
      },
      "outputs": [],
      "source": [
        "segmentation_mask = detection_result.segmentation_masks[0].numpy_view()\n",
        "visualized_mask = np.repeat(segmentation_mask[:, :, np.newaxis], 3, axis=2) * 255\n",
        "cv2_imshow(visualized_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 비디오로 시작하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 1: 필요한 모듈 가져오기\n",
        "import mediapipe as mp\n",
        "import cv2  # OpenCV 라이브러리 추가\n",
        "import numpy as np\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import time # 타임스탬프 생성을 위해 추가\n",
        "\n",
        "# (이전에 정의된 draw_landmarks_on_image 함수가 있다고 가정합니다)\n",
        "# from mediapipe import solutions\n",
        "# from mediapipe.framework.formats import landmark_pb2\n",
        "# def draw_landmarks_on_image(rgb_image, detection_result): ... (이전 코드 참고)\n",
        "\n",
        "# STEP 2: 비디오 처리를 위한 PoseLandmarker 객체 생성\n",
        "# 모델 파일 경로 설정 (사용자 환경에 맞게 수정 필요)\n",
        "model_path = '/Users/laxdin24/Downloads/pose_landmarker_heavy.task'\n",
        "\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "PoseLandmarker = vision.PoseLandmarker\n",
        "PoseLandmarkerOptions = vision.PoseLandmarkerOptions\n",
        "VisionRunningMode = vision.RunningMode\n",
        "\n",
        "# 비디오 모드로 옵션 설정\n",
        "options = PoseLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=model_path),\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        "    output_segmentation_masks=True) # 필요한 경우 세그멘테이션 마스크 출력 설정\n",
        "\n",
        "# STEP 3: 비디오 파일 열기 및 PoseLandmarker 생성\n",
        "video_path = \"your_video.mp4\" # 처리할 비디오 파일 경로로 수정하세요.\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# 비디오의 FPS(초당 프레임 수) 가져오기 (타임스탬프 계산에 사용될 수 있음)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_duration_ms = int(1000 / fps) # 각 프레임의 지속 시간 (밀리초)\n",
        "\n",
        "# PoseLandmarker 객체를 with 문 안에서 생성하여 사용 후 자동 정리\n",
        "with PoseLandmarker.create_from_options(options) as landmarker:\n",
        "    frame_index = 0\n",
        "    while cap.isOpened(): # 비디오가 열려있는 동안 반복\n",
        "        # STEP 4: 비디오에서 프레임 읽기\n",
        "        success, frame = cap.read()\n",
        "        if not success:\n",
        "            print(\"비디오의 끝에 도달했거나 파일을 읽는 데 실패했습니다.\")\n",
        "            break\n",
        "\n",
        "        # STEP 5: 프레임 처리 및 랜드마크 감지\n",
        "        # OpenCV는 기본적으로 BGR 형식으로 이미지를 읽으므로 RGB로 변환\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        # MediaPipe Image 객체로 변환\n",
        "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # 현재 프레임의 타임스탬프 계산 (밀리초 단위)\n",
        "        timestamp_ms = frame_index * frame_duration_ms\n",
        "\n",
        "        # 비디오 모드용 감지 함수 호출 (타임스탬프 필요)\n",
        "        detection_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
        "\n",
        "        # STEP 6: 결과 시각화 (선택 사항)\n",
        "        # 원본 프레임(BGR)을 복사하여 사용 (annotated_image는 RGB를 반환하므로)\n",
        "        annotated_frame_bgr = np.copy(frame)\n",
        "        if detection_result.pose_landmarks:\n",
        "            # draw_landmarks_on_image 함수는 RGB 이미지를 입력으로 받음\n",
        "            annotated_frame_rgb = draw_landmarks_on_image(rgb_frame, detection_result)\n",
        "            # 화면 표시를 위해 다시 BGR로 변환\n",
        "            annotated_frame_bgr = cv2.cvtColor(annotated_frame_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # 결과 프레임 화면에 표시\n",
        "        cv2.imshow('Pose Landmarker - Video', annotated_frame_bgr)\n",
        "\n",
        "        frame_index += 1\n",
        "\n",
        "        # 'q' 키를 누르면 종료\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "# STEP 7: 자원 해제\n",
        "cap.release() # 비디오 캡처 객체 해제\n",
        "cv2.destroyAllWindows() # 모든 OpenCV 창 닫기\n",
        "\n",
        "print(\"비디오 처리가 완료되었습니다.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
