{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/ipykernel_91386/3970136668.py:195: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"í•œêµ­ì‚¬ ë¬¸ì œ ì±—ë´‡\", height=450)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ GPT ì‘ë‹µ ì›ë¬¸:\n",
      " ë¬¸ì œ: ë°±ì œì˜ ì „ì„±ê¸°ë¥¼ ì´ëŒì—ˆë˜ ì™•ìœ¼ë¡œ, í™©í•´ë„ ì§€ì—­ì„ ì ë ¹í•˜ê³  ì¤‘êµ­ ë‚¨ì¡°ì™€ í™œë°œíˆ êµë¥˜í•œ ì™•ì€ ëˆ„êµ¬ì¸ê°€?  \n",
      "ë³´ê¸°:  \n",
      "1. ê³ ì´ì™•  \n",
      "2. ê·¼ì´ˆê³ ì™•  \n",
      "3. ì„±ì™•  \n",
      "4. ë¬´ì™•  \n",
      "ì •ë‹µ: 2  \n",
      "í•´ì„¤: ê·¼ì´ˆê³ ì™•(4ì„¸ê¸°)ì€ ë°±ì œì˜ ì „ì„±ê¸°ë¥¼ ì´ëˆ ì™•ìœ¼ë¡œ, í™©í•´ë„ ì§€ì—­ì„ ì ë ¹í•˜ë©° ì˜í† ë¥¼ í™•ì¥í–ˆê³ , ì¤‘êµ­ ë‚¨ì¡°ì™€ êµë¥˜ë¥¼ í†µí•´ ë°±ì œì˜ êµ­ì œì  ìœ„ìƒì„ ë†’ì˜€ë‹¤.  \n",
      "ğŸ”´ ì˜¤ë¥˜: Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py\", line 198, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py\", line 445, in request\n",
      "    self.endheaders()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 1293, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 1052, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 990, in send\n",
      "    self.connect()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py\", line 276, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py\", line 213, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x1794b0610>: Failed to establish a new connection: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /save-question (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1794b0610>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/ipykernel_91386/3970136668.py\", line 103, in add_chat\n",
      "    save_res = requests.post(\"http://localhost:8000/save-question\", data={\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/adapters.py\", line 700, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /save-question (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1794b0610>: Failed to establish a new connection: [Errno 61] Connection refused'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from openai import AzureOpenAI\n",
    "import traceback\n",
    "\n",
    "\n",
    "# Azure OpenAI ì„¤ì •\n",
    "client = AzureOpenAI(\n",
    "    api_key=\"\",\n",
    "    azure_endpoint=\"https://6b013-azure-ai-service.openai.azure.com/\",\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")\n",
    "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "\n",
    "# ì¹´ë“œ ì—…ë°ì´íŠ¸\n",
    "def update_cards(title_text):\n",
    "    return title_text, title_text, title_text\n",
    "\n",
    "# ì˜¤ë‹µ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "def fetch_wrong_answers_cards(user_id=1):\n",
    "    try:\n",
    "        res = requests.get(\"http://localhost:8000/get-wrong-answers\", params={\"user_id\": user_id})\n",
    "        data = res.json()[\"wrong_answers\"]\n",
    "\n",
    "        if not data:\n",
    "            return \"âœ… ì˜¤ë‹µì´ ì—†ìŠµë‹ˆë‹¤!\"\n",
    "\n",
    "        cards = []\n",
    "        for idx, item in enumerate(data, 1):\n",
    "            q = f\"**{idx}. ë¬¸ì œ:** {item['question_text']}\"\n",
    "            choices = \"\\n\".join([\n",
    "                f\"   - â‘  {item['choice1']}\",\n",
    "                f\"   - â‘¡ {item['choice2']}\",\n",
    "                f\"   - â‘¢ {item['choice3']}\",\n",
    "                f\"   - â‘£ {item['choice4']}\"\n",
    "            ])\n",
    "            answer = f\"âœ… ì •ë‹µ: {item['answer']}ë²ˆ\"\n",
    "            my_choice = f\"âŒ ë‚´ ì„ íƒ: {item['user_choice']}ë²ˆ\"\n",
    "            exp = f\"ğŸ“˜ í•´ì„¤: {item['explanation']}\"\n",
    "            cards.append(f\"{q}\\n{choices}\\n{answer} | {my_choice}\\n{exp}\")\n",
    "\n",
    "        return \"\\n\\n---\\n\\n\".join(cards)\n",
    "    except Exception as e:\n",
    "        return f\"â— ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "def update_wrong_note_textbox():\n",
    "    text = fetch_wrong_answers_cards()\n",
    "    return gr.update(value=text)\n",
    "\n",
    "\n",
    "# ë¬¸ì œ ìƒì„±\n",
    "\n",
    "def add_chat(user_msg, history):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    history.append((user_msg, None))\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "ë„ˆëŠ” í•œêµ­ì‚¬ëŠ¥ë ¥ê²€ì •ì‹œí—˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” AI íŠœí„°ì•¼.\n",
    "ì ˆëŒ€ë¡œ ì•„ë˜ í˜•ì‹ì„ ë²—ì–´ë‚˜ì§€ ë§ˆ. ë‹¤ë¥¸ ë¬¸ì¥ ì¶”ê°€ ê¸ˆì§€.\n",
    "\n",
    "í˜•ì‹ ì˜ˆì‹œ:\n",
    "ë¬¸ì œ: ë°±ì œì˜ ìˆ˜ë„ê°€ í•œì„±ì—ì„œ ì›…ì§„ìœ¼ë¡œ ì˜®ê²¨ì§„ ì´ìœ ëŠ”?\n",
    "ë³´ê¸°:\n",
    "1. ì‹ ë¼ì™€ì˜ ë™ë§¹\n",
    "2. ê³ êµ¬ë ¤ì˜ ì¹¨ì…\n",
    "3. ë‚´ë¶€ ë°˜ë€\n",
    "4. ì¼ë³¸ê³¼ì˜ ê´€ê³„ ì•…í™”\n",
    "ì •ë‹µ: 2\n",
    "í•´ì„¤: 475ë…„ ê³ êµ¬ë ¤ ì¥ìˆ˜ì™•ì˜ ê³µê²©ìœ¼ë¡œ ë°±ì œ ìˆ˜ë„ í•œì„±ì´ í•¨ë½ë˜ì—ˆê³ , ë¬¸ì£¼ì™•ì€ ì›…ì§„ìœ¼ë¡œ ì²œë„í•˜ì˜€ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=AZURE_DEPLOYMENT_NAME,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        result = completion.choices[0].message.content\n",
    "        print(\"ğŸ“¦ GPT ì‘ë‹µ ì›ë¬¸:\\n\", result)\n",
    "\n",
    "        if all(k in result for k in [\"ë¬¸ì œ:\", \"ë³´ê¸°:\", \"ì •ë‹µ:\", \"í•´ì„¤:\"]):\n",
    "            parts = result.split(\"ë¬¸ì œ:\")[1].strip().split(\"ë³´ê¸°:\")\n",
    "            question = parts[0].strip()\n",
    "            choice_lines = parts[1].split(\"ì •ë‹µ\")[0].strip().split(\"\\n\")\n",
    "            choices = [line.strip() for line in choice_lines if line.strip()]\n",
    "            answer = int(result.split(\"ì •ë‹µ:\")[1].split(\"\\n\")[0].strip())\n",
    "            explanation = result.split(\"í•´ì„¤:\")[1].strip()\n",
    "        else:\n",
    "            raise ValueError(\"GPT ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ìš”.\")\n",
    "\n",
    "        save_res = requests.post(\"http://localhost:8000/save-question\", data={\n",
    "            \"material_id\": 12,\n",
    "            \"question_text\": question,\n",
    "            \"choice1\": choices[0],\n",
    "            \"choice2\": choices[1],\n",
    "            \"choice3\": choices[2],\n",
    "            \"choice4\": choices[3],\n",
    "            \"answer\": answer,\n",
    "            \"explanation\": explanation\n",
    "        })\n",
    "        question_id = save_res.json().get(\"question_id\", )\n",
    "\n",
    "        ai_text = question + \"\\n\" + \"\\n\".join(choices)\n",
    "        history.append((None, ai_text))\n",
    "\n",
    "        ai_response = {\n",
    "            \"ë¬¸ì œ\": question,\n",
    "            \"ë³´ê¸°\": choices,\n",
    "            \"ì •ë‹µ\": answer - 1,\n",
    "            \"í•´ì„¤\": explanation,\n",
    "            \"question_id\": question_id\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ğŸ”´ ì˜¤ë¥˜:\", traceback.format_exc())\n",
    "        history.append((None, f\"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}\"))\n",
    "        ai_response = {\"ì •ë‹µ\": 0, \"í•´ì„¤\": \"N/A\", \"question_id\": 0}\n",
    "\n",
    "    return history, ai_response\n",
    "\n",
    "# ì •ë‹µ ì²´í¬ ë° ì˜¤ë‹µ ì €ì¥ í¬í•¨\n",
    "def check_answer(user_choice, ai_response, history):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    correct = ai_response[\"ì •ë‹µ\"] + 1\n",
    "    explanation = ai_response[\"í•´ì„¤\"]\n",
    "    result = \"âœ… ì •ë‹µì…ë‹ˆë‹¤!\" if int(user_choice) == correct else f\"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct}ë²ˆì´ì—ìš”.\"\n",
    "\n",
    "    history.append((f\"ì •ë‹µ: {user_choice}ë²ˆ\", None))\n",
    "    history.append((None, f\"{result}\\nğŸ“˜ í•´ì„¤: {explanation}\"))\n",
    "\n",
    "    if int(user_choice) != correct:\n",
    "        try:\n",
    "            requests.post(\"http://localhost:8000/save_wrong_answer\", data={\n",
    "                \"user_id\": 1,\n",
    "                \"question_id\": ai_response[\"question_id\"],\n",
    "                \"user_choice\": int(user_choice)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(\"â— ì˜¤ë‹µ ì €ì¥ ì‹¤íŒ¨:\", e)\n",
    "\n",
    "    return history\n",
    "\n",
    "# ì „ì²´ UI\n",
    "def build_ui():\n",
    "    with gr.Blocks(title=\"í•œêµ­ì‚¬ëŠ¥ë ¥ê²€ì •ì‹œí—˜ AI í•™ìŠµ\") as demo:\n",
    "        with gr.Tabs():\n",
    "            with gr.TabItem(\"AI ë¬¸ì œ\"):\n",
    "                gr.Markdown(\"### ğŸ’¬ AI ë¬¸ì œ - RAG ê¸°ë°˜ GPT-4o ë¬¸ì œ ìƒì„±\")\n",
    "                chatbot = gr.Chatbot(label=\"í•œêµ­ì‚¬ ë¬¸ì œ ì±—ë´‡\", height=450)\n",
    "                state = gr.State([])\n",
    "                ai_state = gr.State({})\n",
    "\n",
    "                with gr.Row():\n",
    "                    user_input = gr.Textbox(placeholder=\"ì˜ˆ: ë°±ì œ ë¬¸í™” ê´€ë ¨ ë¬¸ì œ ë‚´ì¤˜\", label=\"ë¬¸ì œ ìš”ì²­\", scale=8)\n",
    "                    send_btn = gr.Button(\"ìš”ì²­\", scale=2)\n",
    "\n",
    "                answer_dropdown = gr.Radio(choices=[\"1\", \"2\", \"3\", \"4\"], label=\"ì •ë‹µ ì„ íƒ\", visible=False)\n",
    "                submit_answer = gr.Button(\"ì •ë‹µ ì œì¶œ\", visible=False)\n",
    "\n",
    "                send_btn.click(fn=add_chat, inputs=[user_input, state], outputs=[chatbot, ai_state])\n",
    "                send_btn.click(lambda: gr.update(visible=True), outputs=answer_dropdown)\n",
    "                send_btn.click(lambda: gr.update(visible=True), outputs=submit_answer)\n",
    "                submit_answer.click(fn=check_answer, inputs=[answer_dropdown, ai_state, state], outputs=chatbot)\n",
    "\n",
    "            with gr.TabItem(\"ğŸ“• ì˜¤ë‹µ ë…¸íŠ¸\"):\n",
    "                gr.Markdown(\"## ğŸ“• ë‚˜ì˜ ì˜¤ë‹µ ë…¸íŠ¸ (ë¦¬ìŠ¤íŠ¸ ë³´ê¸°)\")\n",
    "                wrong_note_output = gr.Textbox(lines=20, interactive=False, label=\"ì˜¤ë‹µ ëª©ë¡\", show_copy_button=True)\n",
    "                refresh_btn = gr.Button(\"ğŸ” ì˜¤ë‹µ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
    "                refresh_btn.click(fn=update_wrong_note_textbox, inputs=[], outputs=[wrong_note_output])\n",
    "\n",
    "    return demo\n",
    "\n",
    "demo = build_ui()\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ì½”ë“œì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/ipykernel_91386/2937927437.py:247: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"í•œêµ­ì‚¬ ë¬¸ì œ ì±—ë´‡\", height=500, bubble_full_width=False)\n",
      "/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/ipykernel_91386/2937927437.py:247: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(label=\"í•œêµ­ì‚¬ ë¬¸ì œ ì±—ë´‡\", height=500, bubble_full_width=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ GPT ì‘ë‹µ ì›ë¬¸:\n",
      " ë¬¸ì œ: ë°±ì œì˜ ê±´êµ­ ì‹œì¡°ëŠ” ëˆ„êµ¬ì¸ê°€?  \n",
      "ë³´ê¸°:  \n",
      "1. ì£¼ëª½  \n",
      "2. ì˜¨ì¡°  \n",
      "3. ë°•í˜ê±°ì„¸  \n",
      "4. ì´ì„±ê³„  \n",
      "ì •ë‹µ: 2  \n",
      "í•´ì„¤: ë°±ì œëŠ” ê³ êµ¬ë ¤ì—ì„œ ë‚´ë ¤ì˜¨ ì˜¨ì¡°ê°€ í•œê°• ìœ ì—­ì—ì„œ ê±´êµ­í•œ ë‚˜ë¼ì´ë‹¤. ì˜¨ì¡°ëŠ” ì£¼ëª½ì˜ ì•„ë“¤ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤.  \n",
      "ğŸ”´ ì˜¤ë¥˜: âŒ ë¬¸ì œ ì €ì¥ API í˜¸ì¶œ ì‹¤íŒ¨: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /save-question (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x17edff410>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "# from datetime import datetime # ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°\n",
    "from openai import AzureOpenAI\n",
    "import traceback\n",
    "import json # JSONDecodeError ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€\n",
    "\n",
    "# Azure OpenAI ì„¤ì •\n",
    "# ë³´ì•ˆìƒ API í‚¤ëŠ” ì½”ë“œì— ì§ì ‘ í•˜ë“œì½”ë”©í•˜ëŠ” ê²ƒë³´ë‹¤ í™˜ê²½ ë³€ìˆ˜ë‚˜\n",
    "# ë³„ë„ì˜ ì„¤ì • íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "# ì˜ˆ: api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "client = AzureOpenAI(\n",
    "    api_key=\"\",\n",
    "    azure_endpoint=\"https://6b013-azure-ai-service.openai.azure.com/\",\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")\n",
    "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "\n",
    "# ì¹´ë“œ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°)\n",
    "# def update_cards(title_text):\n",
    "#     return title_text, title_text, title_text\n",
    "\n",
    "# ì˜¤ë‹µ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def fetch_wrong_answers_cards(user_id: int = 1) -> str:\n",
    "    \"\"\"ì§€ì •ëœ ì‚¬ìš©ìì˜ ì˜¤ë‹µ ëª©ë¡ì„ APIì—ì„œ ê°€ì ¸ì™€ í¬ë§·íŒ…ëœ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        # íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¶”ê°€ ê¶Œì¥\n",
    "        res = requests.get(\"http://localhost:8000/get-wrong-answers\", params={\"user_id\": user_id}, timeout=10)\n",
    "        res.raise_for_status() # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ\n",
    "        data = res.json().get(\"wrong_answers\", []) # í‚¤ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "\n",
    "        if not data:\n",
    "            return \"âœ… ì˜¤ë‹µì´ ì—†ìŠµë‹ˆë‹¤!\"\n",
    "\n",
    "        cards = []\n",
    "        for idx, item in enumerate(data, 1):\n",
    "            # í•„ìˆ˜ í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ë” ì•ˆì „í•œ ì ‘ê·¼)\n",
    "            q_text = item.get('question_text', 'N/A')\n",
    "            c1 = item.get('choice1', 'N/A')\n",
    "            c2 = item.get('choice2', 'N/A')\n",
    "            c3 = item.get('choice3', 'N/A')\n",
    "            c4 = item.get('choice4', 'N/A')\n",
    "            ans = item.get('answer', 'N/A')\n",
    "            u_choice = item.get('user_choice', 'N/A')\n",
    "            exp = item.get('explanation', 'N/A')\n",
    "\n",
    "            q = f\"**{idx}. ë¬¸ì œ:** {q_text}\"\n",
    "            choices = (\n",
    "                f\"   - â‘  {c1}\\n\"\n",
    "                f\"   - â‘¡ {c2}\\n\"\n",
    "                f\"   - â‘¢ {c3}\\n\"\n",
    "                f\"   - â‘£ {c4}\"\n",
    "            )\n",
    "            answer = f\"âœ… ì •ë‹µ: {ans}ë²ˆ\"\n",
    "            my_choice = f\"âŒ ë‚´ ì„ íƒ: {u_choice}ë²ˆ\"\n",
    "            exp_text = f\"ğŸ“˜ í•´ì„¤: {exp}\"\n",
    "            cards.append(f\"{q}\\n{choices}\\n{answer} | {my_choice}\\n{exp_text}\")\n",
    "\n",
    "        return \"\\n\\n---\\n\\n\".join(cards)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "        return f\"â— API ì—°ê²° ì˜¤ë¥˜: {str(e)}\"\n",
    "    except json.JSONDecodeError:\n",
    "        # JSON íŒŒì‹± ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "        return \"â— API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜ (JSON íŒŒì‹± ì‹¤íŒ¨)\"\n",
    "    except Exception as e:\n",
    "        # ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬\n",
    "        print(f\"ì˜¤ë‹µ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜ˆì™¸ ë°œìƒ: {traceback.format_exc()}\")\n",
    "        return f\"â— ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "\n",
    "def update_wrong_note_textbox() -> gr.Textbox:\n",
    "    \"\"\"ì˜¤ë‹µ ë…¸íŠ¸ í…ìŠ¤íŠ¸ë°•ìŠ¤ë¥¼ ìµœì‹  ì˜¤ë‹µ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\"\"\"\n",
    "    text = fetch_wrong_answers_cards()\n",
    "    return gr.update(value=text)\n",
    "\n",
    "\n",
    "# ë¬¸ì œ ìƒì„±\n",
    "def add_chat(user_msg: str, history: list | None) -> tuple[list, dict]:\n",
    "    \"\"\"ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ AI ëª¨ë¸ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•˜ê³ , ì±„íŒ… ê¸°ë¡ê³¼ AI ì‘ë‹µ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if history is None:\n",
    "        history = []\n",
    "    history.append((user_msg, None)) # ì‚¬ìš©ì ë©”ì‹œì§€ ë¨¼ì € ì¶”ê°€\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "ë„ˆëŠ” í•œêµ­ì‚¬ëŠ¥ë ¥ê²€ì •ì‹œí—˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” AI íŠœí„°ì•¼.\n",
    "ì ˆëŒ€ë¡œ ì•„ë˜ í˜•ì‹ì„ ë²—ì–´ë‚˜ì§€ ë§ˆ. ë‹¤ë¥¸ ë¬¸ì¥ ì¶”ê°€ ê¸ˆì§€.\n",
    "\n",
    "í˜•ì‹ ì˜ˆì‹œ:\n",
    "ë¬¸ì œ: ë°±ì œì˜ ìˆ˜ë„ê°€ í•œì„±ì—ì„œ ì›…ì§„ìœ¼ë¡œ ì˜®ê²¨ì§„ ì´ìœ ëŠ”?\n",
    "ë³´ê¸°:\n",
    "1. ì‹ ë¼ì™€ì˜ ë™ë§¹\n",
    "2. ê³ êµ¬ë ¤ì˜ ì¹¨ì…\n",
    "3. ë‚´ë¶€ ë°˜ë€\n",
    "4. ì¼ë³¸ê³¼ì˜ ê´€ê³„ ì•…í™”\n",
    "ì •ë‹µ: 2\n",
    "í•´ì„¤: 475ë…„ ê³ êµ¬ë ¤ ì¥ìˆ˜ì™•ì˜ ê³µê²©ìœ¼ë¡œ ë°±ì œ ìˆ˜ë„ í•œì„±ì´ í•¨ë½ë˜ì—ˆê³ , ë¬¸ì£¼ì™•ì€ ì›…ì§„ìœ¼ë¡œ ì²œë„í•˜ì˜€ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_msg}\n",
    "    ]\n",
    "\n",
    "    ai_response = {\"ì •ë‹µ\": 0, \"í•´ì„¤\": \"N/A\", \"question_id\": 0} # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=AZURE_DEPLOYMENT_NAME,\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        result = completion.choices[0].message.content\n",
    "        print(\"ğŸ“¦ GPT ì‘ë‹µ ì›ë¬¸:\\n\", result) # ë””ë²„ê¹…ìš© ì¶œë ¥\n",
    "\n",
    "        # --- ì‘ë‹µ íŒŒì‹± ---\n",
    "        # ì´ ë¶€ë¶„ì€ LLM ì‘ë‹µ í˜•ì‹ ë³€í™”ì— ì·¨ì•½í•©ë‹ˆë‹¤. ì •ê·œì‹ ì‚¬ìš©ì´ë‚˜\n",
    "        # ë” êµ¬ì¡°í™”ëœ ì‘ë‹µ í˜•ì‹ì„ ìš”ì²­í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        if not all(k in result for k in [\"ë¬¸ì œ:\", \"ë³´ê¸°:\", \"ì •ë‹µ:\", \"í•´ì„¤:\"]):\n",
    "             raise ValueError(\"GPT ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (í•„ìˆ˜ í‚¤ì›Œë“œ ëˆ„ë½)\")\n",
    "\n",
    "        try:\n",
    "            question = result.split(\"ë¬¸ì œ:\")[1].split(\"ë³´ê¸°:\")[0].strip()\n",
    "            choices_block = result.split(\"ë³´ê¸°:\")[1].split(\"ì •ë‹µ:\")[0].strip()\n",
    "            choices = [line.strip() for line in choices_block.split('\\n') if line.strip()]\n",
    "            if len(choices) != 4:\n",
    "                raise ValueError(f\"ë³´ê¸° í•­ëª©ì´ 4ê°œê°€ ì•„ë‹™ë‹ˆë‹¤. (ì°¾ì€ ê°œìˆ˜: {len(choices)})\")\n",
    "\n",
    "            answer_str = result.split(\"ì •ë‹µ:\")[1].split(\"í•´ì„¤:\")[0].strip()\n",
    "            answer = int(answer_str) # ì •ìˆ˜ ë³€í™˜ ì‹œë„\n",
    "            explanation = result.split(\"í•´ì„¤:\")[1].strip()\n",
    "\n",
    "        except (IndexError, ValueError) as parse_error:\n",
    "            raise ValueError(f\"GPT ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {parse_error}\") from parse_error\n",
    "        # --- íŒŒì‹± ë ---\n",
    "\n",
    "        # --- ë¬¸ì œ ì €ì¥ API í˜¸ì¶œ ---\n",
    "        save_payload = {\n",
    "            \"material_id\": 12, # ì´ ê°’ì€ ë™ì ìœ¼ë¡œ ì„¤ì •ë  ìˆ˜ ìˆì–´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            \"question_text\": question,\n",
    "            \"choice1\": choices[0],\n",
    "            \"choice2\": choices[1],\n",
    "            \"choice3\": choices[2],\n",
    "            \"choice4\": choices[3],\n",
    "            \"answer\": answer,\n",
    "            \"explanation\": explanation\n",
    "        }\n",
    "        # íƒ€ì„ì•„ì›ƒ ì„¤ì • ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”\n",
    "        save_res = requests.post(\"http://localhost:8000/save-question\", data=save_payload, timeout=10)\n",
    "        save_res.raise_for_status() # HTTP ì˜¤ë¥˜ í™•ì¸\n",
    "        question_id = save_res.json().get(\"question_id\")\n",
    "        if question_id is None:\n",
    "            print(\"âš ï¸ ë¬¸ì œ ì €ì¥ API ì‘ë‹µì— question_idê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            # í•„ìš”ì‹œ ì˜ˆì™¸ ë°œìƒ ë˜ëŠ” ê¸°ë³¸ê°’ ì²˜ë¦¬\n",
    "        # --- API í˜¸ì¶œ ë ---\n",
    "\n",
    "        # ì„±ê³µ ì‹œ ì±„íŒ… ê¸°ë¡ ë° ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "        ai_text = question + \"\\n\" + \"\\n\".join(choices) # ì±—ë´‡ì— í‘œì‹œë  í…ìŠ¤íŠ¸\n",
    "        history.append((None, ai_text)) # AI ì‘ë‹µì„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€\n",
    "\n",
    "        ai_response = {\n",
    "            \"ë¬¸ì œ\": question,\n",
    "            \"ë³´ê¸°\": choices,\n",
    "            \"ì •ë‹µ\": answer - 1, # Gradio Radio ì¸ë±ìŠ¤ëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ ì¡°ì •\n",
    "            \"í•´ì„¤\": explanation,\n",
    "            \"question_id\": question_id if question_id is not None else 0 # Noneì¼ ê²½ìš° ê¸°ë³¸ê°’\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"âŒ ë¬¸ì œ ì €ì¥ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}\"\n",
    "        print(f\"ğŸ”´ ì˜¤ë¥˜: {error_msg}\")\n",
    "        history.append((None, error_msg))\n",
    "    except (ValueError, IndexError) as e: # íŒŒì‹± ì˜¤ë¥˜ í¬í•¨\n",
    "        error_msg = f\"âŒ ë¬¸ì œ ìƒì„± ë˜ëŠ” ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\"\n",
    "        print(f\"ğŸ”´ ì˜¤ë¥˜: {error_msg}\\n{traceback.format_exc()}\")\n",
    "        history.append((None, error_msg))\n",
    "    except Exception as e: # OpenAI API ì˜¤ë¥˜ ë“± ê¸°íƒ€ ì˜ˆì™¸\n",
    "        error_msg = f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "        print(f\"ğŸ”´ ì˜¤ë¥˜: {error_msg}\\n{traceback.format_exc()}\")\n",
    "        history.append((None, error_msg))\n",
    "\n",
    "    return history, ai_response\n",
    "\n",
    "# ì •ë‹µ ì²´í¬ ë° ì˜¤ë‹µ ì €ì¥ í¬í•¨\n",
    "def check_answer(user_choice: str | None, ai_response: dict, history: list | None) -> list:\n",
    "    \"\"\"ì‚¬ìš©ìì˜ ì„ íƒì„ ë°›ì•„ ì •ë‹µì„ í™•ì¸í•˜ê³ , ì˜¤ë‹µì¸ ê²½ìš° ì €ì¥í•˜ë©°, ì±„íŒ… ê¸°ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if history is None:\n",
    "        history = []\n",
    "    if user_choice is None:\n",
    "        history.append((None, \"âš ï¸ ì •ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš”.\"))\n",
    "        return history\n",
    "    if not ai_response or \"ì •ë‹µ\" not in ai_response or \"í•´ì„¤\" not in ai_response:\n",
    "         history.append((None, \"âš ï¸ ë¬¸ì œ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ ì±„ì í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"))\n",
    "         return history\n",
    "\n",
    "    try:\n",
    "        user_choice_int = int(user_choice)\n",
    "        # ai_response[\"ì •ë‹µ\"]ì€ 0-based index, user_choiceëŠ” 1-based string\n",
    "        correct_answer_display = ai_response[\"ì •ë‹µ\"] + 1\n",
    "        explanation = ai_response[\"í•´ì„¤\"]\n",
    "\n",
    "        result_msg = f\"âœ… ì •ë‹µì…ë‹ˆë‹¤!\" if user_choice_int == correct_answer_display else f\"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤. ì •ë‹µì€ {correct_answer_display}ë²ˆì´ì—ìš”.\"\n",
    "\n",
    "        # ì‚¬ìš©ìì˜ ì„ íƒê³¼ ê²°ê³¼ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€\n",
    "        history.append((f\"ë‚˜ì˜ ì„ íƒ: {user_choice}ë²ˆ\", None))\n",
    "        history.append((None, f\"{result_msg}\\nğŸ“˜ í•´ì„¤: {explanation}\"))\n",
    "\n",
    "        # ì˜¤ë‹µì¸ ê²½ìš° ì €ì¥ ì‹œë„\n",
    "        if user_choice_int != correct_answer_display:\n",
    "            question_id = ai_response.get(\"question_id\")\n",
    "            if question_id: # question_idê°€ ìœ íš¨í•  ë•Œë§Œ ì €ì¥ ì‹œë„\n",
    "                try:\n",
    "                    # íƒ€ì„ì•„ì›ƒ ì„¤ì • ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”\n",
    "                    wrong_answer_payload = {\n",
    "                        \"user_id\": 1, # ì´ ê°’ë„ ë™ì ìœ¼ë¡œ ì„¤ì •ë  ìˆ˜ ìˆì–´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "                        \"question_id\": question_id,\n",
    "                        \"user_choice\": user_choice_int\n",
    "                    }\n",
    "                    res = requests.post(\"http://localhost:8000/save_wrong_answer\", data=wrong_answer_payload, timeout=10)\n",
    "                    res.raise_for_status() # HTTP ì˜¤ë¥˜ í™•ì¸\n",
    "                    print(f\"â„¹ï¸ ì˜¤ë‹µ ì €ì¥ ì„±ê³µ (Question ID: {question_id})\")\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"â— ì˜¤ë‹µ ì €ì¥ API í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"â— ì˜¤ë‹µ ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ Question IDê°€ ì—†ì–´ ì˜¤ë‹µì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    except ValueError:\n",
    "        history.append((None, \"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì„ íƒì…ë‹ˆë‹¤.\"))\n",
    "    except Exception as e:\n",
    "        history.append((None, f\"âš ï¸ ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"))\n",
    "        print(f\"ì±„ì  ì¤‘ ì˜¤ë¥˜: {traceback.format_exc()}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# ì „ì²´ UI êµ¬ì„±\n",
    "def build_ui() -> gr.Blocks:\n",
    "    \"\"\"Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    with gr.Blocks(title=\"í•œêµ­ì‚¬ëŠ¥ë ¥ê²€ì •ì‹œí—˜ AI í•™ìŠµ\") as demo:\n",
    "        with gr.Tabs():\n",
    "            # --- AI ë¬¸ì œ íƒ­ ---\n",
    "            with gr.TabItem(\"AI ë¬¸ì œ\"):\n",
    "                gr.Markdown(\"### ğŸ’¬ AI ë¬¸ì œ - RAG ê¸°ë°˜ GPT-4o ë¬¸ì œ ìƒì„±\")\n",
    "                # Chatbot ë†’ì´ ì¡°ì • ë° ë ˆì´ì•„ì›ƒ ê°œì„  ê³ ë ¤\n",
    "                chatbot = gr.Chatbot(label=\"í•œêµ­ì‚¬ ë¬¸ì œ ì±—ë´‡\", height=500, bubble_full_width=False)\n",
    "                # state: ì±„íŒ… ê¸°ë¡ (list of tuples)\n",
    "                state = gr.State([])\n",
    "                # ai_state: í˜„ì¬ ë¬¸ì œ ì •ë³´ (dict)\n",
    "                ai_state = gr.State({})\n",
    "\n",
    "                with gr.Row():\n",
    "                    user_input = gr.Textbox(\n",
    "                        placeholder=\"ì˜ˆ: ë°±ì œ ë¬¸í™” ê´€ë ¨ ë¬¸ì œ ë‚´ì¤˜\",\n",
    "                        label=\"ë¬¸ì œ ìš”ì²­\",\n",
    "                        scale=8,\n",
    "                        container=False # í…Œë‘ë¦¬ ì œê±°\n",
    "                    )\n",
    "                    send_btn = gr.Button(\"ìš”ì²­\", scale=2, variant=\"primary\")\n",
    "\n",
    "                # ì •ë‹µ ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼ (ì´ˆê¸°ì—ëŠ” ìˆ¨ê¹€)\n",
    "                answer_dropdown = gr.Radio(\n",
    "                    choices=[\"1\", \"2\", \"3\", \"4\"],\n",
    "                    label=\"ì •ë‹µ ì„ íƒ\",\n",
    "                    visible=False,\n",
    "                    interactive=True\n",
    "                )\n",
    "                # ì •ë‹µ ì œì¶œ ë²„íŠ¼ (ì´ˆê¸°ì—ëŠ” ìˆ¨ê¹€)\n",
    "                submit_answer = gr.Button(\"ì •ë‹µ ì œì¶œ\", visible=False, variant=\"secondary\")\n",
    "\n",
    "                # --- ì´ë²¤íŠ¸ ì—°ê²° ---\n",
    "                # ìš”ì²­ ë²„íŠ¼ í´ë¦­ ì‹œ: add_chat ì‹¤í–‰ -> ì±—ë´‡, ai_state ì—…ë°ì´íŠ¸\n",
    "                send_btn.click(\n",
    "                    fn=add_chat,\n",
    "                    inputs=[user_input, state],\n",
    "                    outputs=[chatbot, ai_state]\n",
    "                ).then( # add_chat ì‹¤í–‰ í›„\n",
    "                    # ì…ë ¥ì°½ ë¹„ìš°ê¸°\n",
    "                    lambda: gr.update(value=\"\"), outputs=[user_input]\n",
    "                ).then(\n",
    "                    # ì •ë‹µ ì„ íƒ ë° ì œì¶œ ë²„íŠ¼ í‘œì‹œ\n",
    "                    lambda: (gr.update(visible=True), gr.update(visible=True)),\n",
    "                    outputs=[answer_dropdown, submit_answer]\n",
    "                )\n",
    "\n",
    "                # ì—”í„° í‚¤ë¡œ ìš”ì²­ ë³´ë‚´ê¸°\n",
    "                user_input.submit(\n",
    "                    fn=add_chat,\n",
    "                    inputs=[user_input, state],\n",
    "                    outputs=[chatbot, ai_state]\n",
    "                ).then(\n",
    "                    lambda: gr.update(value=\"\"), outputs=[user_input]\n",
    "                ).then(\n",
    "                    lambda: (gr.update(visible=True), gr.update(visible=True)),\n",
    "                    outputs=[answer_dropdown, submit_answer]\n",
    "                )\n",
    "\n",
    "                # ì •ë‹µ ì œì¶œ ë²„íŠ¼ í´ë¦­ ì‹œ: check_answer ì‹¤í–‰ -> ì±—ë´‡ ì—…ë°ì´íŠ¸\n",
    "                submit_answer.click(\n",
    "                    fn=check_answer,\n",
    "                    inputs=[answer_dropdown, ai_state, state],\n",
    "                    outputs=[chatbot]\n",
    "                ).then( # check_answer ì‹¤í–‰ í›„\n",
    "                    # ì •ë‹µ ì„ íƒ ë¹„í™œì„±í™” ë° ì œì¶œ ë²„íŠ¼ ìˆ¨ê¸°ê¸° (ìƒˆ ë¬¸ì œ ìš”ì²­ ì „ê¹Œì§€)\n",
    "                    lambda: (gr.update(interactive=False), gr.update(visible=False)),\n",
    "                    outputs=[answer_dropdown, submit_answer]\n",
    "                )\n",
    "\n",
    "            # --- ì˜¤ë‹µ ë…¸íŠ¸ íƒ­ ---\n",
    "            with gr.TabItem(\"ğŸ“• ì˜¤ë‹µ ë…¸íŠ¸\"):\n",
    "                gr.Markdown(\"## ğŸ“• ë‚˜ì˜ ì˜¤ë‹µ ë…¸íŠ¸ (ë¦¬ìŠ¤íŠ¸ ë³´ê¸°)\")\n",
    "                wrong_note_output = gr.Textbox(\n",
    "                    lines=20,\n",
    "                    interactive=False,\n",
    "                    label=\"ì˜¤ë‹µ ëª©ë¡\",\n",
    "                    show_copy_button=True\n",
    "                )\n",
    "                refresh_btn = gr.Button(\"ğŸ” ì˜¤ë‹µ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
    "\n",
    "                # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ í´ë¦­ ì‹œ: update_wrong_note_textbox ì‹¤í–‰ -> ì˜¤ë‹µ ë…¸íŠ¸ ì—…ë°ì´íŠ¸\n",
    "                refresh_btn.click(\n",
    "                    fn=update_wrong_note_textbox,\n",
    "                    inputs=[],\n",
    "                    outputs=[wrong_note_output]\n",
    "                )\n",
    "                # íƒ­ì´ ì„ íƒë  ë•Œ ìë™ìœ¼ë¡œ ì˜¤ë‹µ ë…¸íŠ¸ ë¡œë“œ (ì„ íƒ ì‚¬í•­)\n",
    "                # wrong_note_output.attach_load_event(update_wrong_note_textbox, every=None) # Gradio ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "    return demo\n",
    "\n",
    "# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    demo = build_ui()\n",
    "    # share=True ì˜µì…˜ì€ ì™¸ë¶€ ê³µìœ  ë§í¬ ìƒì„± ì‹œ ì‚¬ìš©\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
