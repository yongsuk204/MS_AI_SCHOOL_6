{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfcc0c8",
   "metadata": {},
   "source": [
    "# RAG 이전 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9202bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import re\n",
    "\n",
    "# 🔐 API 설정\n",
    "endpoint_chat = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "key_chat = \"\"\n",
    "key_speech = \"\"\n",
    "region_speech = \"eastus2\"\n",
    "\n",
    "# 📷 이미지 → base64\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 🧼 특수문자 제거\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text) # [ 여기에 넣어서 제거 ]\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "# 🗣️ 음성 생성\n",
    "def speak_text(text, speed=\"0%\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"ko-KR-HyunsuMultilingualNeural\">\n",
    "        <prosody rate=\"{speed}\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=key_speech, region=region_speech)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# 🤖 GPT 응답 요청2\n",
    "def get_api_response(max_chars=400, base64_image=None):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": key_chat}\n",
    "    user_prompt = f\"1.이미지는 대한 내용에 대해서 자세하게 설명해줘. 2.한국사능력검정시험에서 자주 출제되는 문제를 기반하여 종합적으로 분석해서 설명해줘. 3.전체 분량은 약 {max_chars}자에 꼭 맞춰서 간결하고 완결성 있게 작성해줘.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"한국사능력검정시험 준비를 위한 정보를 제공합니다. 가능한 자세하고 구체적으로 설명해주세요.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    if base64_image:\n",
    "        messages.insert(1, {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}]})\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(endpoint_chat, headers=headers, json=payload)\n",
    "        res.raise_for_status()\n",
    "        return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        return f\"API 오류: {e}\"\n",
    "\n",
    "# 🎯 전체 통합 함수\n",
    "def chatbot_with_duration(image, speed_label, duration_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    duration_map = {\"1분\": 380, \"3분\": 800, \"5분\": 2000, \"10분\": 5000}\n",
    "\n",
    "    rate = speed_map[speed_label]\n",
    "    max_chars = duration_map[duration_label]\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    raw_answer = get_api_response(max_chars, base64_image)\n",
    "    cleaned = clean_special_characters(raw_answer)\n",
    "    audio = speak_text(cleaned, rate)\n",
    "\n",
    "    return cleaned, audio\n",
    "\n",
    "# 🖼️ Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 요약 및 음성화\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"말하기 속도\", value=\"1배속\")\n",
    "            duration = gr.Radio([\"1분\", \"3분\", \"5분\", \"10분\"], label=\"TTS 길이\", value=\"1분\")\n",
    "            submit = gr.Button(\"응답 받기\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### 📜 응답\")\n",
    "            answer = gr.Textbox(label=\"GPT 응답\", lines=10)\n",
    "            gr.Markdown(\"### 🗣️들으면서 공부하자\")\n",
    "            audio = gr.Audio(label=\"음성 출력\", autoplay=True)\n",
    "\n",
    "    image.change(fn=chatbot_with_duration, inputs=[image, speed, duration], outputs=[answer, audio])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab8bb5e",
   "metadata": {},
   "source": [
    "# RAG 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import re\n",
    "\n",
    "# 🔐 API 설정\n",
    "endpoint_chat = \"https://6b013-azure-ai-service.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "key_chat = \"\"\n",
    "search_endpoint=\"https://6b013-ai-search-3.search.windows.net\"\n",
    "search_key=\"\"\n",
    "search_index=\"history-index\"\n",
    "\n",
    "key_speech = \"\"\n",
    "region_speech = \"eastus2\"\n",
    "\n",
    "# 📷 이미지 → base64\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 🧼 특수문자 제거\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text) # [ 여기에 넣어서 제거 ]\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "# 🗣️ 음성 생성\n",
    "def speak_text(text, speed=\"0%\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"ko-KR-HyunsuMultilingualNeural\">\n",
    "        <prosody rate=\"{speed}\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=key_speech, region=region_speech)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# 🤖 GPT 응답 요청\n",
    "def get_api_response_1(max_chars=400, base64_image=None):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": key_chat}\n",
    "    user_prompt = f\"1.이미지는 대한 내용에 대해서 자세하게 설명해줘. 2.한국사능력검정시험에서 자주 출제되는 문제를 기반하여 종합적으로 분석해서 설명해줘. 3.전체 분량은 약 {max_chars}자에 꼭 맞춰서 간결하고 완결성 있게 작성해줘.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"한국사능력검정시험 준비를 위한 정보를 제공합니다. 가능한 자세하고 구체적으로 설명하며, 이모지,*,/,#을 포함하지않는 줄글 형식으로 작성합니다.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    if base64_image:\n",
    "        messages.insert(1, {\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}]})\n",
    "\n",
    "    payload = {\n",
    "  \"messages\": messages,\n",
    "  \"temperature\": 0.3,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 4000,\n",
    "  \"data_sources\": [\n",
    "    {\n",
    "      \"type\": \"azure_search\",\n",
    "      \"parameters\": {\n",
    "        \"endpoint\": \"https://6b013-ai-search-3.search.windows.net\",\n",
    "        \"index_name\": \"history-index\",\n",
    "        \"semantic_configuration\": \"history\",\n",
    "        \"query_type\": \"semantic\",\n",
    "        \"fields_mapping\": {\n",
    "          \"content_fields\": [\"content\"],\n",
    "          \"title_field\": \"title\"\n",
    "        },\n",
    "        \"in_scope\": True,\n",
    "        \"strictness\": 3,\n",
    "        \"top_n_documents\": 5,\n",
    "        \"authentication\": {\n",
    "          \"type\": \"api_key\",\n",
    "          \"key\": \"\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "    try:\n",
    "        res = requests.post(endpoint_chat, headers=headers, json=payload)\n",
    "        res.raise_for_status()\n",
    "        return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        return f\"API 오류: {e}\"\n",
    "\n",
    "# 🎯 전체 통합 함수\n",
    "def chatbot_with_duration(image, speed_label, duration_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    duration_map = {\"1분\": 380, \"3분\": 800, \"5분\": 2000, \"10분\": 5000}\n",
    "\n",
    "    rate = speed_map[speed_label]\n",
    "    max_chars = duration_map[duration_label]\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    raw_answer = get_api_response_1(max_chars, base64_image)\n",
    "    cleaned = clean_special_characters(raw_answer)\n",
    "    audio = speak_text(cleaned, rate)\n",
    "\n",
    "    return cleaned, audio\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 요약 및 음성화\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"말하기 속도\", value=\"1배속\")\n",
    "            duration = gr.Radio([\"1분\", \"3분\", \"5분\", \"10분\"], label=\"TTS 길이\", value=\"1분\")\n",
    "            submit = gr.Button(\"응답 받기\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### 📜 응답\")\n",
    "            answer = gr.Textbox(label=\"GPT 응답\", lines=10)\n",
    "            gr.Markdown(\"### 🗣️ 들으면서 공부하자\")\n",
    "            audio = gr.Audio(label=\"음성 출력\", autoplay=True)\n",
    "\n",
    "    submit.click(fn=chatbot_with_duration, inputs=[image, speed, duration], outputs=[answer, audio])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc949f6",
   "metadata": {},
   "source": [
    "# 챗봇2개 섞어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f57e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# 🔐 API 키 및 엔드포인트 설정\n",
    "openai_vision_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_vision_key = \"\"\n",
    "\n",
    "openai_rag_endpoint = \"https://6b013-azure-ai-service.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_rag_key = \"\"\n",
    "\n",
    "search_endpoint = \"https://6b013-ai-search-3.search.windows.net\"\n",
    "search_key = \"\"\n",
    "\n",
    "speech_key = \"\"\n",
    "speech_region = \"eastus2\"\n",
    "\n",
    "# 📷 이미지 → base64\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 🧼 특수문자 제거\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 🗣️ 음성 생성\n",
    "def speak_text(text, speed=\"0%\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"ko-KR-HyunsuMultilingualNeural\">\n",
    "        <prosody rate=\"{speed}\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# 🤖 GPT Vision 요약 - RAG 친화형\n",
    "def get_vision_summary(base64_image, max_chars=600):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_vision_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"이 이미지는 한국사능력검정시험 필기 자료입니다. \"\n",
    "                \"이미지의 내용을 분석하여 RAG 모델이 이해할 수 있도록 \"\n",
    "                \"완성된 문장과 구조로 정리된 요약 지식을 작성하세요. \"\n",
    "                \"불완전한 메모가 아니라, 설명형 텍스트로 작성하고 문장은 자연스럽게 끝나야 합니다.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        f\"이 이미지를 바탕으로 한국사능력검정시험 스타일로 {max_chars}자 이내로 핵심 개념과 맥락을 정리해주세요. \"\n",
    "                        \"사건, 시대, 인물, 개념을 중심으로 서술형으로 작성하며, 문장은 완결된 줄글 형태로 마무리하세요.\"\n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    res = requests.post(openai_vision_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 🤖 GPT RAG 답변 - Vision 지문 기반 고급 응답\n",
    "def get_rag_answer(input_text, max_chars=800):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_rag_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"당신은 한국사능력검정시험 전문가입니다. \"\n",
    "                \"사용자가 제공하는 필기 요약 지문을 바탕으로 출제자의 관점에서 \"\n",
    "                \"중요한 배경지식, 핵심개념, 역사적 비교나 연관성을 포함한 응답을 작성합니다. \"\n",
    "                \"신뢰도 높은 사료와 관련 키워드를 중심으로 설명하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"다음은 필기 이미지로부터 생성된 요약 지문입니다. \"\n",
    "                f\"{max_chars}자 이내로 한국사능력검정시험 스타일로 마무리된 설명문을 작성해주세요.\\n\\n\"\n",
    "                f\"요약 지문:\\n\\\"\\\"\\\"\\n{input_text}\\n\\\"\\\"\\\"\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"frequency_penalty\": 0.25,\n",
    "        \"data_sources\": [\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": search_endpoint,\n",
    "                    \"index_name\": \"history-index\",\n",
    "                    \"semantic_configuration\": \"history\",\n",
    "                    \"query_type\": \"semantic\",\n",
    "                    \"fields_mapping\": {\n",
    "                        \"content_fields\": [\"content\"],\n",
    "                        \"title_field\": \"title\"\n",
    "                    },\n",
    "                    \"in_scope\": True,\n",
    "                    \"strictness\": 3,\n",
    "                    \"top_n_documents\": 3,\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": search_key\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    res = requests.post(openai_rag_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 🎯 통합 파이프라인\n",
    "def process_image_pipeline(image, speed_label, duration_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    duration_map = {\"1분\": 600, \"3분\": 1500, \"5분\": 3500, \"10분\": 5000}\n",
    "\n",
    "    rate = speed_map[speed_label]\n",
    "    max_chars = duration_map[duration_label]\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    vision_summary = get_vision_summary(base64_image, max_chars=max_chars)\n",
    "    rag_answer = get_rag_answer(vision_summary, max_chars=max_chars)\n",
    "    cleaned = clean_special_characters(rag_answer)\n",
    "    audio = speak_text(cleaned, rate)\n",
    "\n",
    "    return vision_summary, cleaned, audio\n",
    "\n",
    "# 🖼️ Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 → 요약 → RAG 응답 → 음성 출력\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"말하기 속도\", value=\"1배속\")\n",
    "            duration = gr.Radio([\"1분\", \"3분\", \"5분\", \"10분\"], label=\"TTS 길이\", value=\"1분\")\n",
    "            submit = gr.Button(\"응답 받기\")\n",
    "        with gr.Column():\n",
    "            vision_output = gr.Textbox(label=\"1️⃣ GPT Vision 요약\", lines=3)\n",
    "            rag_output = gr.Textbox(label=\"2️⃣ RAG 최종 응답\", lines=10)\n",
    "            audio = gr.Audio(label=\"🎧 음성 출력\", autoplay=False)\n",
    "\n",
    "    submit.click(fn=process_image_pipeline, inputs=[image, speed, duration], outputs=[vision_output, rag_output, audio])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f396457",
   "metadata": {},
   "source": [
    "# 최종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# 🔐 API 키 및 엔드포인트 설정\n",
    "openai_vision_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_vision_key = \"\"\n",
    "\n",
    "openai_rag_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_rag_key = \"\"\n",
    "\n",
    "search_endpoint = \"https://6a026-proj2-stor.search.windows.net\"\n",
    "search_key = \"\"\n",
    "\n",
    "speech_key = \"\"\n",
    "speech_region = \"eastus2\"\n",
    "\n",
    "# 이미지 → base64\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 특수문자 제거\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 음성 생성\n",
    "def speak_text(text, speed=\"0%\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"ko-KR-HyunsuMultilingualNeural\">\n",
    "        <prosody rate=\"{speed}\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# GPT Vision 요약\n",
    "def get_vision_summary(base64_image):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_vision_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"이 이미지는 한국사능력검정시험 필기 자료입니다. \"\n",
    "                \"이미지의 내용을 분석하여 RAG 모델이 이해할 수 있도록 \"\n",
    "                \"완성된 문장과 구조로 정리된 요약 지식을 작성하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        f\"이미지의 내용을 한국사능력검정시험 개념과 맥락으로 키워드중심으로 모두 대답해주세요. \"\n",
    "                        \"사건, 시대, 인물, 개념을 중심으로 서술형으로 작성하며, 문장은 완결된 줄글 형태로 마무리하세요.\"\n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    res = requests.post(openai_vision_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# GPT RAG 응답\n",
    "def get_rag_answer_with_citations(input_text, max_chars=350):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_rag_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"당신은 한국사능력검정시험 전문가입니다. \"\n",
    "                \"사용자가 제공하는 키워드중심 필기 요약 지문을 바탕으로 출제자의 관점에서 한국사능력검정시험에 도움이 되는 내용을 중점으로 응답을 작성하세요\"\n",
    "                \"문서를 기반한 내용을 포함하여 신뢰도 높은 사료와 관련 키워드를 중심으로 설명하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"{input_text}를(을) 문서를 기반으로 {max_chars}자에 근접하게 맞추어 한국사능력검정시험을 응시자에게 도움이되게 설명문을 작성해주세요.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"frequency_penalty\": 0.25,\n",
    "        \"data_sources\": [\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": search_endpoint,\n",
    "                    \"index_name\": \"index-026history-csvfile\",\n",
    "                    \"semantic_configuration\": \"026history-csvfile-semantic\",\n",
    "                    \"query_type\": \"semantic\",\n",
    "                    \"fields_mapping\": {\n",
    "                        \"content_fields\": [\"tags\", \"content\", \"category\", \"title\"],\n",
    "                        \"title_field\": \"title\"\n",
    "                    },\n",
    "                    \"in_scope\": True,\n",
    "                    \"role_information\": \"\",\n",
    "                    \"filter\": None,\n",
    "                    \"strictness\": 3,\n",
    "                    \"top_n_documents\": 5,\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": search_key\n",
    "                    },\n",
    "                    \"key\": search_key,\n",
    "                    \"indexName\": \"index-026history-csvfile\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    res = requests.post(openai_rag_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    result = res.json()\n",
    "    content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    citations = result[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "    return {\"answer\": content, \"citations\": citations}\n",
    "\n",
    "# 🔗 출처 포맷\n",
    "def format_citations(citations):\n",
    "    if not citations:\n",
    "        return \"🔍 관련 문서 없음\"\n",
    "    formatted = []\n",
    "    for i, c in enumerate(citations, 1):\n",
    "        title = c.get(\"title\", \"제목 없음\")\n",
    "        url = c.get(\"url\", \"\")\n",
    "        content_citation = c.get(\"content\", \"\")\n",
    "        entry = f\"[{i}] {title} - {content_citation}\"\n",
    "        # URL이 있는 경우에만 추가\n",
    "        if url:\n",
    "            entry += f\" - {url}\"\n",
    "        formatted.append(entry)\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "\n",
    "# 🧠 전체 파이프라인 함수\n",
    "def process_image_pipeline(image, speed_label, duration_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    duration_map = {\"1분\": 300, \"3분\": 700, \"5분\": 3000}\n",
    "\n",
    "    rate = speed_map[speed_label]\n",
    "    max_chars = duration_map[duration_label]\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    vision_summary = get_vision_summary(base64_image)\n",
    "    rag_result = get_rag_answer_with_citations(vision_summary, max_chars=max_chars)\n",
    "\n",
    "    rag_text = clean_special_characters(rag_result[\"answer\"])\n",
    "    citations = format_citations(rag_result.get(\"citations\", []))\n",
    "    audio = speak_text(rag_text, rate)\n",
    "\n",
    "    return vision_summary, rag_text, audio, citations\n",
    "\n",
    "# 🧩 Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 → GPT 요약 → RAG 응답 → 음성 출력 + 🔗 출처 문서 표시\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"말하기 속도\", value=\"1배속\")\n",
    "            duration = gr.Radio([\"1분\", \"3분\", \"5분\"], label=\"TTS 길이\", value=\"1분\")\n",
    "            submit = gr.Button(\"응답 받기\")\n",
    "        with gr.Column():\n",
    "            vision_output = gr.Textbox(label=\"1️⃣ GPT Vision 요약\", lines=3)\n",
    "            rag_output = gr.Textbox(label=\"2️⃣ RAG 최종 응답\", lines=10)\n",
    "            audio = gr.Audio(label=\"🎧 음성 출력\", autoplay=False)\n",
    "            citations_box = gr.Textbox(label=\"🔗 출처 문서\", lines=5)\n",
    "\n",
    "    submit.click(fn=process_image_pipeline,\n",
    "                 inputs=[image, speed, duration],\n",
    "                 outputs=[vision_output, rag_output, audio, citations_box])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8588c03",
   "metadata": {},
   "source": [
    "# 도식화하기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: on_underlying_io_bytes_received: Close frame received\n",
      "Info: on_underlying_io_bytes_received: closing underlying io.\n",
      "Info: on_underlying_io_close_complete: uws_state: 6.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "from graphviz import Digraph\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# 환경변수에서 API 키 등 로드 (또는 수동 입력 가능)\n",
    "openai_vision_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_vision_key = \"\"\n",
    "\n",
    "openai_rag_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_rag_key = \"\"\n",
    "\n",
    "search_endpoint = \"https://6a026-proj2-stor.search.windows.net\"\n",
    "search_key = \"\"\n",
    "\n",
    "speech_key = \"\"\n",
    "speech_region = \"eastus2\"\n",
    "\n",
    "# === 유틸리티 함수들 ===\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def speak_text(text, speed=\"0%\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"ko-KR-HyunsuMultilingualNeural\">\n",
    "        <prosody rate=\"{speed}\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "def get_vision_summary(base64_image):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_vision_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"이 이미지는 한국사능력검정시험 필기 자료입니다. \"\n",
    "                \"이미지의 내용을 분석하여 RAG 모델이 이해할 수 있도록 \"\n",
    "                \"완성된 문장과 구조로 정리된 요약 지식을 작성하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        f\"이미지의 내용을 한국사능력검정시험 개념과 맥락으로 키워드중심으로 모두 대답해주세요. \"\n",
    "                        \"사건, 시대, 인물, 개념을 중심으로 서술형으로 작성하며, 문장은 완결된 줄글 형태로 마무리하세요.\"\n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\"messages\": messages, \"temperature\": 0.2, \"top_p\": 0.95, \"max_tokens\": 4096}\n",
    "    res = requests.post(openai_vision_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def get_rag_answer_with_citations(input_text, max_chars=350):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_rag_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"당신은 한국사능력검정시험 전문가입니다. \"\n",
    "                \"사용자가 제공하는 키워드중심 필기 요약 지문을 바탕으로 출제자의 관점에서 한국사능력검정시험에 도움이 되는 내용을 중점으로 응답을 작성하세요\"\n",
    "                \"문서를 기반한 내용을 포함하여 신뢰도 높은 사료와 관련 키워드를 중심으로 설명하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"{input_text}를(을) 문서를 기반으로 {max_chars}자에 근접하게 맞추어 한국사능력검정시험을 응시자에게 도움이되게 설명문을 작성해주세요.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"frequency_penalty\": 0.25,\n",
    "        \"data_sources\": [\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": search_endpoint,\n",
    "                    \"index_name\": \"index-026history-csvfile\",\n",
    "                    \"semantic_configuration\": \"026history-csvfile-semantic\",\n",
    "                    \"query_type\": \"semantic\",\n",
    "                    \"fields_mapping\": {\n",
    "                        \"content_fields\": [\"tags\", \"content\", \"category\", \"title\"],\n",
    "                        \"title_field\": \"title\"\n",
    "                    },\n",
    "                    \"in_scope\": True,\n",
    "                    \"strictness\": 3,\n",
    "                    \"top_n_documents\": 3,\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": search_key\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    res = requests.post(openai_rag_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    result = res.json()\n",
    "    content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    citations = result[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "    return {\"answer\": content, \"citations\": citations}\n",
    "\n",
    "# 출처참조 텍스트 정리\n",
    "def format_citations(citations):\n",
    "    if not citations:\n",
    "        return \"🔍 관련 문서 없음\"\n",
    "    formatted = []\n",
    "    for i, c in enumerate(citations, 1):\n",
    "        title = c.get(\"title\", \"제목 없음\")\n",
    "        url = c.get(\"url\", \"\")\n",
    "        content_citation = c.get(\"content\", \"\")\n",
    "        entry = f\"[{i}] {title} - {content_citation}\"\n",
    "        if url:\n",
    "            entry += f\" - {url}\"\n",
    "        formatted.append(entry)\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# 줄바꿈 함수 (한 줄당 최대 40자)\n",
    "def wrap_text(text, max_len=40):\n",
    "    return \"\\\\n\".join(re.findall(f\".{{1,{max_len}}}\", text.strip()))\n",
    "\n",
    "# 트리 시각화 (출처 기반)\n",
    "def generate_citation_tree(text, citations, max_nodes_per_citation=3):\n",
    "    dot = Digraph(format='png')\n",
    "    dot.attr(rankdir='LR', splines='true', dpi='300')\n",
    "    dot.attr(ratio='auto', nodesep='0.7', ranksep='1', margin='0.3,0.3')\n",
    "    dot.attr('node', fontname=\"Malgun Gothic\", fontsize='10', margin='0.1,0.05',\n",
    "             shape='box', style='rounded,filled', fillcolor='lightgrey')\n",
    "    dot.node('summary', '📖 요약문장 도식화')\n",
    "\n",
    "    # 문장을 . ! ? 로 나누기\n",
    "    sentences = re.split(r'[.!?]\\s*', text.strip())\n",
    "\n",
    "    for i, citation in enumerate(citations, 1):\n",
    "        title = citation.get(\"title\", f\"출처 {i}\")\n",
    "        content = citation.get(\"content\", \"\")\n",
    "        src_node = f\"src_{i}\"\n",
    "\n",
    "        label = wrap_text(f\"[{i}] {title}\\n{content[:-len(title)]}\")\n",
    "        dot.node(src_node, label, shape=\"ellipse\", fillcolor=\"lightyellow\")\n",
    "        dot.edge(\"summary\", src_node)\n",
    "\n",
    "        child_count = 0  # 연결된 문장 수 추적\n",
    "\n",
    "        for j, sent in enumerate(sentences):\n",
    "            if child_count >= max_nodes_per_citation:\n",
    "                break  # 최대 개수 초과 시 중단\n",
    "            if any(kw in sent for kw in [title] + content.split()):\n",
    "                node_id = f\"{src_node}_{j}\"\n",
    "                wrapped_sent = wrap_text(sent, max_len=35)\n",
    "                dot.node(node_id, wrapped_sent, shape=\"note\", fillcolor=\"white\")\n",
    "                dot.edge(src_node, node_id)\n",
    "                child_count += 1  # 문장 연결 수 카운트\n",
    "\n",
    "    return dot.render(\"tree_output\", format='png', cleanup=False)\n",
    "\n",
    "# 전체 파이프라인 실행 함수\n",
    "def process_image_pipeline(image, speed_label, duration_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    duration_map = {\"1분\": 300, \"3분\": 700, \"5분\": 2000}\n",
    "\n",
    "    rate = speed_map[speed_label]\n",
    "    max_chars = duration_map[duration_label]\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    vision_summary = get_vision_summary(base64_image)\n",
    "    rag_result = get_rag_answer_with_citations(vision_summary, max_chars=max_chars)\n",
    "    rag_text = clean_special_characters(rag_result[\"answer\"])\n",
    "    citations = rag_result.get(\"citations\", [])\n",
    "    citations_text = format_citations(citations)\n",
    "    audio = speak_text(rag_text, rate)\n",
    "    tree_path = generate_citation_tree(rag_text, citations)\n",
    "\n",
    "    return vision_summary, rag_text, audio, citations_text, tree_path\n",
    "\n",
    "# Gradio UI 구성\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 → GPT 요약 → RAG 응답 → 음성 출력 + 출처 기반 트리 도식화\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"📷 필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"🗣️ 말하기 속도\", value=\"1배속\")\n",
    "            duration = gr.Radio([\"1분\", \"3분\", \"5분\"], label=\"⏱️ TTS 길이\", value=\"1분\")\n",
    "            submit = gr.Button(\"🧠 응답 받기\")\n",
    "        with gr.Column():\n",
    "            vision_output = gr.Textbox(label=\"1️⃣ GPT Vision 요약\", lines=3)\n",
    "            rag_output = gr.Textbox(label=\"2️⃣ RAG 최종 응답\", lines=10)\n",
    "            audio = gr.Audio(label=\"🎧 음성 출력\", autoplay=False)\n",
    "            citations_box = gr.Textbox(label=\"🔗 출처 문서\", lines=5)\n",
    "    with gr.Row():\n",
    "        tree_output = gr.Image(label=\"🌳 출처 기반 트리 시각화\", type=\"filepath\")\n",
    "\n",
    "    submit.click(fn=process_image_pipeline,\n",
    "                 inputs=[image, speed, duration],\n",
    "                 outputs=[vision_output, rag_output, audio, citations_box, tree_output])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf09906",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacdea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: on_underlying_io_bytes_received: Close frame received\n",
      "Info: on_underlying_io_bytes_received: closing underlying io.\n",
      "Info: on_underlying_io_close_complete: uws_state: 6.\n",
      "Info: on_underlying_io_bytes_received: Close frame received\n",
      "Info: on_underlying_io_bytes_received: closing underlying io.\n",
      "Info: on_underlying_io_close_complete: uws_state: 6.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import base64\n",
    "from graphviz import Digraph\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "\n",
    "# 🔐 API 키 및 환경 설정\n",
    "openai_vision_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_vision_key = \"\"\n",
    "\n",
    "openai_rag_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_rag_key = \"\"\n",
    "\n",
    "search_endpoint = \"https://6a026-proj2-stor.search.windows.net\"\n",
    "search_key = \"\"\n",
    "\n",
    "speech_key = \"\"\n",
    "speech_region = \"eastus2\"\n",
    "\n",
    "# 📸 이미지 → base64\n",
    "def image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ✂️ 텍스트 클린업\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 🔈 음성 생성\n",
    "def speak_text(text, speed=\"0%\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"ko-KR-HyunsuMultilingualNeural\">\n",
    "        <prosody rate=\"{speed}\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# 🧠 Vision 요약\n",
    "def get_vision_summary(base64_image):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_vision_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"이 이미지는 한국사능력검정시험 필기 자료입니다. \"\n",
    "                \"이미지의 내용을 분석하여 RAG 모델이 이해할 수 있도록 \"\n",
    "                \"완성된 문장과 구조로 정리된 요약 지식을 작성하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        f\"이미지의 내용을 한국사능력검정시험 개념과 맥락으로 키워드중심으로 모두 대답해주세요. \"\n",
    "                        \"사건, 시대, 인물, 개념을 중심으로 서술형으로 작성하며, 문장은 완결된 줄글 형태로 마무리하세요.\"\n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\"messages\": messages, \"temperature\": 0.2, \"top_p\": 0.95, \"max_tokens\": 4096}\n",
    "    res = requests.post(openai_vision_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 📚 RAG 응답\n",
    "def get_rag_answer_with_citations(input_text, max_chars=350):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_rag_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"당신은 한국사능력검정시험 전문가입니다. \"\n",
    "                \"사용자가 제공하는 키워드중심 필기 요약 지문을 바탕으로 출제자의 관점에서 한국사능력검정시험에 도움이 되는 내용을 중점으로 응답을 작성하세요\"\n",
    "                \"문서를 기반한 내용을 포함하여 신뢰도 높은 사료와 관련 키워드를 중심으로 설명하세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"{input_text}를(을) 문서를 기반으로 {max_chars}자에 근접하게 맞추어 한국사능력검정시험을 응시자에게 도움이되게 설명문을 작성해주세요.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"frequency_penalty\": 0.25,\n",
    "        \"data_sources\": [\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": search_endpoint,\n",
    "                    \"index_name\": \"index-026history-csvfile\",\n",
    "                    \"semantic_configuration\": \"026history-csvfile-semantic\",\n",
    "                    \"query_type\": \"semantic\",\n",
    "                    \"fields_mapping\": {\n",
    "                        \"content_fields\": [\"tags\", \"content\", \"category\", \"title\"],\n",
    "                        \"title_field\": \"title\"\n",
    "                    },\n",
    "                    \"in_scope\": True,\n",
    "                    \"strictness\": 3,\n",
    "                    \"top_n_documents\": 5,\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": search_key\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    res = requests.post(openai_rag_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    result = res.json()\n",
    "    return {\n",
    "        \"answer\": result[\"choices\"][0][\"message\"][\"content\"],\n",
    "        \"citations\": result[\"choices\"][0][\"message\"].get(\"context\", {}).get(\"citations\", [])\n",
    "    }\n",
    "\n",
    "# 🔗 출처 포맷\n",
    "def format_citations(citations):\n",
    "    if not citations:\n",
    "        return \"🔍 관련 문서 없음\"\n",
    "    formatted = []\n",
    "    for i, c in enumerate(citations, 1):\n",
    "        title = c.get(\"title\", \"제목 없음\")\n",
    "        url = c.get(\"url\", \"\")\n",
    "        content_citation = c.get(\"content\", \"\")\n",
    "        entry = f\"[{i}] {title} - {content_citation}\"\n",
    "        if url:\n",
    "            entry += f\" - {url}\"\n",
    "        formatted.append(entry)\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# ✂️ 텍스트 줄바꿈\n",
    "def wrap_text(text, max_len=40, max_lines=3):\n",
    "    lines = re.findall(f\".{{1,{max_len}}}\", text.strip())\n",
    "    if len(lines) > max_lines:\n",
    "        return \"\\\\n\".join(lines[:max_lines]) + \"\\\\n...\"\n",
    "    return \"\\\\n\".join(lines)\n",
    "\n",
    "# 🌳 출처 기반 트리 생성\n",
    "def generate_citation_tree(text, citations, max_nodes_per_citation=3):\n",
    "    dot = Digraph(format='png')\n",
    "    dot.attr(rankdir='LR', splines='true', dpi='300')\n",
    "    dot.attr(ratio='auto', nodesep='0.7', ranksep='1', margin='0.3,0.3')\n",
    "    dot.attr('node', fontname=\"Malgun Gothic\", fontsize='10', margin='0.1,0.05',\n",
    "             shape='box', style='rounded,filled', fillcolor='lightgrey')\n",
    "    dot.node('summary', '📖 요약문장 도식화')\n",
    "\n",
    "    sentences = re.split(r'[.!?]\\s*', text.strip())\n",
    "\n",
    "    for i, citation in enumerate(citations, 1):\n",
    "        title = citation.get(\"title\", f\"출처 {i}\")\n",
    "        content = citation.get(\"content\", \"\")\n",
    "        src_node = f\"src_{i}\"\n",
    "        label = wrap_text(f\"[{i}] {title}\\n{content[:-len(title)]}\")\n",
    "        dot.node(src_node, label, shape=\"ellipse\", fillcolor=\"lightyellow\")\n",
    "        dot.edge(\"summary\", src_node)\n",
    "\n",
    "        child_count = 0\n",
    "        for j, sent in enumerate(sentences):\n",
    "            if child_count >= max_nodes_per_citation:\n",
    "                break\n",
    "            if any(kw in sent for kw in [title] + content.split()):\n",
    "                node_id = f\"{src_node}_{j}\"\n",
    "                wrapped_sent = wrap_text(sent, max_len=35)\n",
    "                dot.node(node_id, wrapped_sent, shape=\"note\", fillcolor=\"white\")\n",
    "                dot.edge(src_node, node_id)\n",
    "                child_count += 1\n",
    "\n",
    "    return dot.render(\"tree_output\", format='png', cleanup=False)\n",
    "\n",
    "# 🚀 전체 파이프라인\n",
    "def process_image_pipeline(image, speed_label, duration_label, max_nodes_per_citation):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    duration_map = {\"1분\": 300, \"3분\": 700, \"5분\": 2000}\n",
    "    rate = speed_map[speed_label]\n",
    "    max_chars = duration_map[duration_label]\n",
    "\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "    vision_summary = get_vision_summary(base64_image)\n",
    "    rag_result = get_rag_answer_with_citations(vision_summary, max_chars=max_chars)\n",
    "    rag_text = clean_special_characters(rag_result[\"answer\"])\n",
    "    citations = rag_result.get(\"citations\", [])\n",
    "    citations_text = format_citations(citations)\n",
    "    audio = speak_text(rag_text, rate)\n",
    "    tree_path = generate_citation_tree(rag_text, citations, max_nodes_per_citation=max_nodes_per_citation)\n",
    "\n",
    "    return vision_summary, rag_text, audio, citations_text, tree_path\n",
    "\n",
    "# 🧩 Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 → GPT 요약 → RAG 응답 → 음성 출력 + 출처 기반 트리 도식화\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"📷 필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"🗣️ 말하기 속도\", value=\"1배속\")\n",
    "            duration = gr.Radio([\"1분\", \"3분\", \"5분\"], label=\"⏱️ TTS 길이\", value=\"1분\")\n",
    "            max_nodes_slider = gr.Slider(minimum=1, maximum=10, step=1, value=3,\n",
    "                                         label=\"🌿 출처당 연결 문장 수 (노드 제한)\")\n",
    "            submit = gr.Button(\"🧠 응답 받기\")\n",
    "\n",
    "        with gr.Column():\n",
    "            vision_output = gr.Textbox(label=\"1️⃣ GPT Vision 요약\", lines=3)\n",
    "            rag_output = gr.Textbox(label=\"2️⃣ RAG 최종 응답\", lines=10)\n",
    "            audio = gr.Audio(label=\"🎧 음성 출력\", autoplay=False)\n",
    "            citations_box = gr.Textbox(label=\"🔗 출처 문서\", lines=5)\n",
    "\n",
    "    with gr.Row():\n",
    "        tree_output = gr.Image(label=\"🌳 출처 기반 트리 시각화\", type=\"filepath\")\n",
    "\n",
    "    submit.click(\n",
    "        fn=process_image_pipeline,\n",
    "        inputs=[image, speed, duration, max_nodes_slider],\n",
    "        outputs=[vision_output, rag_output, audio, citations_box, tree_output]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
