{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: on_underlying_io_bytes_received: Close frame received\n",
      "Info: on_underlying_io_bytes_received: closing underlying io.\n",
      "Info: on_underlying_io_close_complete: uws_state: 6.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# 🔐 API 키 및 엔드포인트 설정\n",
    "openai_vision_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_vision_key = \"\"\n",
    "\n",
    "openai_rag_endpoint = \"\"\n",
    "openai_rag_key = \"\"\n",
    "\n",
    "speech_key = \"\"\n",
    "speech_region = \"eastus2\"\n",
    "\n",
    "# 🖼️ 이미지 → base64 변환\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# 🧹 특수문자 정리\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 🗣️ 음성 생성 (SSML + 속도 조절 + 음성 선택)\n",
    "def speak_text(text, speed=\"0%\", voice_name=\"ko-KR-HyunsuMultilingualNeural\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"{voice_name}\">\n",
    "        <prosody rate=\\\"{speed}\\\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# 👁️ GPT Vision OCR\n",
    "def get_vision_ocr(base64_image):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_vision_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"이 이미지는 한국사 필기 자료입니다. 이미지에 포함된 텍스트를 문맥에 맞게 정리하여 글을 작성하세요. \"\n",
    "                \"그리고 추출된 내용 외에도 관련된 역사적 사건, 시대적 배경, 인물, 제도, 흐름 등을 보완하여 설명하세요. \"\n",
    "                \"한국사능력검정시험을 준비하는 수험생에게 도움이 되는 형태로 서술해 주세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\"type\": \"text\", \"text\": \"이미지의 텍스트를 바탕으로 전체 맥락을 풍부하게 설명해주세요.\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    res = requests.post(openai_vision_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 💡 RAG 기반 GPT 요약\n",
    "def get_rag_answer(input_text, target_tokens=500, target_chars=300):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_rag_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"당신은 한국사능력검정시험 전문가입니다. 주어진 지문을 요약하고 역사적 배경과 키워드를 설명하세요. \"\n",
    "                f\"요약은 반드시 {target_chars}자 이내로 작성하세요. \"\n",
    "                \"가능하다면 해당 제한에 최대한 가까운 길이로 작성해 주세요. 줄글 형식으로 서술하십시오.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"다음은 필기 이미지로부터 생성된 지문입니다:\\n\\\"\\\"\\\"\\n{input_text}\\n\\\"\\\"\\\"\"\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": target_tokens,\n",
    "        \"frequency_penalty\": 0.25\n",
    "    }\n",
    "    res = requests.post(openai_rag_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 🎯 전체 파이프라인\n",
    "def process_image_pipeline(image, speed_label, char_label, voice_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    voice_map = {\n",
    "        \"👩‍🦰 여자1\": \"ko-KR-SunHiNeural\",\n",
    "        \"👩 여자2\": \"ko-KR-SoonBokNeural\",\n",
    "        \"👨 남자1\": \"ko-KR-InJoonNeural\",\n",
    "        \"👨‍🦱 남자2\": \"ko-KR-HyunsuMultilingualNeural\"\n",
    "    }\n",
    "    char_token_map = {\n",
    "        \"약 500자 요약 (1분 예상)\": (500, 300),\n",
    "        \"약 1000자 요약 (3분 예상)\": (1000, 800),\n",
    "        \"약 1500자 요약 (5분 예상)\": (2500, 2100)\n",
    "    }\n",
    "    # 속도, 음성, 요약 길이 설정\n",
    "    rate = speed_map[speed_label]\n",
    "    voice_name = voice_map[voice_label]\n",
    "    target_chars, target_tokens = char_token_map[char_label]\n",
    "\n",
    "    # 그라디오에 사용되게 이미지 처리\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    # GPT Vision OCR\n",
    "    vision_summary = get_vision_ocr(base64_image)\n",
    "    # GPT RAG 요약\n",
    "    rag_answer = get_rag_answer(vision_summary, target_tokens=target_tokens, target_chars=target_chars)\n",
    "\n",
    "    # 특수문자없애기\n",
    "    rag_output_text = clean_special_characters(rag_answer)\n",
    "    vision_summary_text = clean_special_characters(vision_summary)\n",
    "\n",
    "    # 음성생성\n",
    "    audio = speak_text(rag_output_text, rate, voice_name)\n",
    "\n",
    "    # rag_output_text = f\"[총 {len(cleaned)}자] \" + cleaned\n",
    "    # vision_summary_text = f\"[총 {len(cleaned_v)}자] \" + cleaned_v\n",
    "    return vision_summary_text, rag_output_text, audio\n",
    "\n",
    "# 🖼️ Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 → GPT 요약 → 음성 출력\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"말하기 속도\", value=\"1배속\")\n",
    "            chars = gr.Radio(\n",
    "                [\"약 500자 요약 (1분 예상)\", \"약 1000자 요약 (3분 예상)\", \"약 1500자 요약 (5분 예상)\"],\n",
    "                label=\"요약 길이 (글자 수 기준)\",\n",
    "                value=\"약 500자 요약 (1분 예상)\"\n",
    "            )\n",
    "            voice = gr.Radio(\n",
    "                [\"👩‍🦰 여자1\", \"👩 여자2\", \"👨 남자1\", \"👨‍🦱 남자2\"],\n",
    "                label=\"TTS 음성 선택\",\n",
    "                value=\"👨‍🦱 남자2\"\n",
    "            )\n",
    "            submit = gr.Button(\"응답 받기\")\n",
    "        with gr.Column():\n",
    "            vision_output = gr.Textbox(label=\"1️⃣ GPT Vision OCR\", lines=3)\n",
    "            rag_output = gr.Textbox(label=\"2️⃣ 요약 결과\", lines=10)\n",
    "            audio = gr.Audio(label=\"🎧 음성 출력\", autoplay=False)\n",
    "\n",
    "    submit.click(\n",
    "        fn=process_image_pipeline,\n",
    "        inputs=[image, speed, chars, voice],\n",
    "        outputs=[vision_output, rag_output, audio]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import base64\n",
    "import re\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# 🔐 API 키 및 엔드포인트 설정\n",
    "openai_vision_endpoint = \"https://a026-proj2-openai2.openai.azure.com/openai/deployments/gpt-4o-2/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_vision_key = \"\"\n",
    "\n",
    "openai_rag_endpoint = \"https://6b013-azure-ai-service.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-02-15-preview\"\n",
    "openai_rag_key = \"\"\n",
    "\n",
    "speech_key = \"\"\n",
    "speech_region = \"eastus2\"\n",
    "\n",
    "# 🖼️ 이미지 → base64 변환\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# 🧹 특수문자 정리\n",
    "def clean_special_characters(text):\n",
    "    text = re.sub(\"[\\U00010000-\\U0010ffff]\", \"\", text)\n",
    "    text = re.sub(r'[*#\\\\/]', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 🗣️ 음성 생성 (SSML + 속도 조절 + 음성 선택)\n",
    "def speak_text(text, speed=\"0%\", voice_name=\"ko-KR-HyunsuMultilingualNeural\"):\n",
    "    ssml = f\"\"\"\n",
    "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\" xml:lang=\"ko-KR\">\n",
    "      <voice name=\"{voice_name}\">\n",
    "        <prosody rate=\\\"{speed}\\\">{text}</prosody>\n",
    "      </voice>\n",
    "    </speak>\n",
    "    \"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)\n",
    "    result = synthesizer.speak_ssml_async(ssml).get()\n",
    "    return result.audio_data if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted else None\n",
    "\n",
    "# 👁️ GPT Vision OCR\n",
    "def get_vision_ocr(base64_image):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_vision_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"이 이미지는 한국사 필기 자료입니다. 이미지에 포함된 텍스트를 문맥에 맞게 정리하여 글을 작성하세요. \"\n",
    "                \"그리고 추출된 내용 외에도 관련된 역사적 사건, 시대적 배경, 인물, 제도, 흐름 등을 보완하여 설명하세요. \"\n",
    "                \"한국사능력검정시험을 준비하는 수험생에게 도움이 되는 형태로 서술해 주세요.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\"type\": \"text\", \"text\": \"이미지의 텍스트를 바탕으로 전체 맥락을 풍부하게 설명해주세요.\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    res = requests.post(openai_vision_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 💡 RAG 기반 GPT 요약\n",
    "def get_rag_answer(input_text, target_tokens=500, target_chars=300):\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai_rag_key}\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"당신은 한국사능력검정시험 전문가입니다. 주어진 지문을 요약하고 역사적 배경과 키워드를 설명하세요. \"\n",
    "                f\"요약은 반드시 {target_chars}자 이내로 작성하세요. \"\n",
    "                \"가능하다면 해당 제한에 최대한 가까운 길이로 작성해 주세요. 줄글 형식으로 서술하십시오.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"다음은 필기 이미지로부터 생성된 지문입니다:\\n\\\"\\\"\\\"\\n{input_text}\\n\\\"\\\"\\\"\"\n",
    "        }\n",
    "    ]\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        \"max_tokens\": target_tokens,\n",
    "        \"frequency_penalty\": 0.25\n",
    "    }\n",
    "    res = requests.post(openai_rag_endpoint, headers=headers, json=payload)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# 🎯 전체 파이프라인\n",
    "def process_image_pipeline(image, speed_label, char_label, voice_label):\n",
    "    speed_map = {\"1배속\": \"0%\", \"1.5배속\": \"50%\", \"2배속\": \"100%\"}\n",
    "    voice_map = {\n",
    "        \"👩‍🦰 여자1\": \"ko-KR-SunHiNeural\",\n",
    "        \"👩 여자2\": \"ko-KR-SoonBokNeural\",\n",
    "        \"👨 남자1\": \"ko-KR-InJoonNeural\",\n",
    "        \"👨‍🦱 남자2\": \"ko-KR-HyunsuMultilingualNeural\"\n",
    "    }\n",
    "    char_token_map = {\n",
    "        \"약 500자 요약 (1분 예상)\": (500, 300),\n",
    "        \"약 1000자 요약 (3분 예상)\": (1000, 800),\n",
    "        \"약 1500자 요약 (5분 예상)\": (2500, 2100)\n",
    "    }\n",
    "    # 속도, 음성, 요약 길이 설정\n",
    "    rate = speed_map[speed_label]\n",
    "    voice_name = voice_map[voice_label]\n",
    "    target_chars, target_tokens = char_token_map[char_label]\n",
    "\n",
    "    # 그라디오에 사용되게 이미지 처리\n",
    "    base64_image = image_to_base64(image) if image else None\n",
    "\n",
    "    # GPT Vision OCR\n",
    "    vision_summary = get_vision_ocr(base64_image)\n",
    "    # GPT RAG 요약\n",
    "    rag_answer = get_rag_answer(vision_summary, target_tokens=target_tokens, target_chars=target_chars)\n",
    "\n",
    "    # 특수문자없애기\n",
    "    rag_output_text = clean_special_characters(rag_answer)\n",
    "\n",
    "    # 음성생성\n",
    "    audio = speak_text(rag_output_text, rate, voice_name)\n",
    "\n",
    "    # rag_output_text = f\"[총 {len(cleaned)}자] \" + cleaned\n",
    "    # vision_summary_text = f\"[총 {len(cleaned_v)}자] \" + cleaned_v\n",
    "    return rag_output_text, audio\n",
    "\n",
    "# 🖼️ Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 📚 한국사 필기노트 → GPT 요약 → 음성 출력\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            image = gr.Image(type=\"filepath\", label=\"필기 이미지 업로드\")\n",
    "            speed = gr.Radio([\"1배속\", \"1.5배속\", \"2배속\"], label=\"말하기 속도\", value=\"1배속\")\n",
    "            chars = gr.Radio(\n",
    "                [\"약 500자 요약 (1분 예상)\", \"약 1000자 요약 (3분 예상)\", \"약 1500자 요약 (5분 예상)\"],\n",
    "                label=\"요약 길이 (글자 수 기준)\",\n",
    "                value=\"약 500자 요약 (1분 예상)\"\n",
    "            )\n",
    "            voice = gr.Radio(\n",
    "                [\"👩‍🦰 여자1\", \"👩 여자2\", \"👨 남자1\", \"👨‍🦱 남자2\"],\n",
    "                label=\"TTS 음성 선택\",\n",
    "                value=\"👨‍🦱 남자2\"\n",
    "            )\n",
    "            submit = gr.Button(\"응답 받기\")\n",
    "        with gr.Column():\n",
    "            vision_output = gr.Textbox(label=\"1️⃣ GPT Vision OCR\", lines=3)\n",
    "            rag_output = gr.Textbox(label=\"2️⃣ 요약 결과\", lines=10)\n",
    "            audio = gr.Audio(label=\"🎧 음성 출력\", autoplay=False)\n",
    "\n",
    "    submit.click(\n",
    "        fn=process_image_pipeline,\n",
    "        inputs=[image, speed, chars, voice],\n",
    "        outputs=[vision_output, rag_output, audio]\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
