{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 📌 cv2.cvtColor() / 이미지 색상형태 변경\n",
    "\n",
    "`cv2.cvtColor()` 함수는 **OpenCV에서 색 공간 변환**을 수행하는 함수입니다.  \n",
    "이미지의 색상 형식을 변경할 때 사용되며, 대표적으로 **RGB ↔ Grayscale 변환, RGB ↔ HSV 변환** 등에 사용됩니다.\n",
    "\n",
    "🔹 기본 문법\n",
    "```python\n",
    "cv2.cvtColor(src, code)\n",
    "src = \"변환할 원본이미지(NumPy 배열)\"\n",
    "code = \"변활할 색공간 코드 (cv2.CLOOR_???형태)\"\n",
    "```\n",
    "✅ `cv2.cvtColor()` 정리\n",
    "\n",
    "| 변환 코드 | 설명 |\n",
    "|-----------|--------------------------------------|\n",
    "| `cv2.COLOR_BGR2GRAY` | 컬러(BGR) → 흑백(Grayscale) 변환 |\n",
    "| `cv2.COLOR_GRAY2BGR` | 흑백(Grayscale) → 컬러(BGR) 변환 |\n",
    "| `cv2.COLOR_BGR2RGB` | OpenCV(BGR) → 표준 RGB 변환 |\n",
    "| `cv2.COLOR_RGB2BGR` | 표준 RGB → OpenCV(BGR) 변환 |\n",
    "| `cv2.COLOR_BGR2HSV` | BGR → HSV 변환 (색상 필터링에 유용) |\n",
    "| `cv2.COLOR_HSV2BGR` | HSV → BGR 변환 |\n",
    "| `cv2.COLOR_BGR2LAB` | BGR → LAB 변환 (밝기 조정에 유용) |\n",
    "| `cv2.COLOR_LAB2BGR` | LAB → BGR 변환 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_1 = cv2.imread(\"people.jpg\")\n",
    "\n",
    "# 색상 변경\n",
    "gray_image = cv2.cvtColor(image_1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "cv2.imshow(\"Image\", gray_image)    # Image 라는 이름으로 image_1 이미지 보여줌\n",
    "cv2.waitKey(0)  # 기다려(아무입력이 입력될때까지)\n",
    "cv2.destroyAllWindows   # 창 닫음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 이미지에 네모칸 바운딩박스 그리기\n",
    " \n",
    " ## 📌 detectMultiScale()\n",
    "\n",
    "`detectMultiScale()`의 파라미터 값 설명\n",
    "\n",
    "`scaleFactor` (1.1)\n",
    "- 이미지 크기를 조절하는 **스케일링 계수**.\n",
    "- 값이 작을수록 더 정확한 탐지가 가능하지만, 속도가 느려짐.\n",
    "- 일반적으로 **1.1~1.3**을 사용.\n",
    "- 값의 의미:\n",
    "  - **1.1**: 매우 촘촘한 스케일 → **정확도 높음, 속도 느림**.\n",
    "  - **1.2 ~ 1.3**: 적당한 탐색 속도 → **속도와 정확도의 균형**.\n",
    "\n",
    "---\n",
    "\n",
    "`minNeighbors` (4)\n",
    "- 후보 사각형(rectangles)이 **겹쳐야 할 최소 개수** (경계를 구분할 때 참조할 주변 픽셀 수).\n",
    "- 높은 값일수록 **오탐(False Positive) 감소**, 하지만 너무 높으면 실제 얼굴도 감지되지 않을 수 있음.\n",
    "- 일반적으로 **3~6**을 사용.\n",
    "- 값의 의미:\n",
    "  - **2~3**: 민감하지만 노이즈가 많을 수 있음.\n",
    "  - **4~6**: 더 강력한 필터링 적용됨 → **더 신뢰할 수 있는 감지 결과**.\n",
    "\n",
    " ## 📌 **cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')**\n",
    "\n",
    "이 코드는 OpenCV의 **Haar Cascade 분류기**를 사용하여 얼굴을 감지하는 데 필요한 모델을 로드하는 역할을 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "🔹 `cv2.CascadeClassifier()`\n",
    "- **Haar Cascade 분류기를 초기화**하는 함수.\n",
    "- 사전 학습된 모델(`.xml` 파일)을 불러와서 **객체(얼굴 등)를 감지**할 수 있도록 설정.\n",
    "\n",
    "✅ `cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')`\n",
    "- OpenCV에 내장된 **정면 얼굴 감지 모델**을 로드하는 코드.\n",
    "- `'haarcascade_frontalface_default.xml'`은 OpenCV에서 제공하는 **사전 학습된 Haar Cascade 얼굴 검출기**.\n",
    "- `cv2.data.haarcascades`는 OpenCV에서 제공하는 **기본 모델이 저장된 경로**를 가져오는 함수.\n",
    "\n",
    "---\n",
    "\n",
    "🔹 `haarcascade_frontalface_default.xml`\n",
    "- **Haar Cascade 기반의 얼굴 감지 모델**.\n",
    "- **흑백 이미지를 입력받아 얼굴의 특징을 감지**하는 방식.\n",
    "- **Haar 특징 기반 필터**를 이용해 얼굴과 비슷한 영역을 찾아냄.\n",
    "\n",
    "---\n",
    "\n",
    "📌 다른 Haar Cascade 모델들\n",
    "\n",
    "| 모델 파일명 | 감지 대상 |\n",
    "|-------------|-----------|\n",
    "| `haarcascade_frontalface_default.xml` | 정면 얼굴 |\n",
    "| `haarcascade_frontalface_alt.xml` | 정면 얼굴 (다른 버전) |\n",
    "| `haarcascade_profileface.xml` | 옆모습 얼굴 |\n",
    "| `haarcascade_eye.xml` | 눈 감지 |\n",
    "| `haarcascade_smile.xml` | 웃는 얼굴 감지 |\n",
    "\n",
    "---\n",
    "\n",
    "✅ 정리\n",
    "\n",
    "| 코드 | 설명 |\n",
    "|------|------|\n",
    "| `cv2.CascadeClassifier()` | Haar Cascade 분류기 객체 생성 |\n",
    "| `cv2.data.haarcascades` | OpenCV에서 제공하는 사전 학습된 모델이 있는 경로 |\n",
    "| `'haarcascade_frontalface_default.xml'` | 정면 얼굴 감지 모델 로드 |\n",
    "\n",
    "Haar Cascade 방식은 **빠르고 가벼운 대신, 정확도가 CNN보다 낮고 조명 변화에 약함**.  \n",
    "더 정확한 얼굴 감지를 위해서는 **딥러닝 기반의 `dnn` 또는 `Mediapipe` 사용**도 고려할 수 있습니다! 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cv2.data.haarcascades       # 여기경로에 얼굴에 대한 정보가 담긴게 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image_1 = cv2.imread(\"people.jpg\")\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#                                            경로                  얼굴을 감지하는 모델\n",
    "faces = face_cascade.detectMultiScale(image_1, 1.1, 4)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image_1, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", image_1)    # Image 라는 이름으로 image_1 이미지 보여줌\n",
    "cv2.waitKey(0)  # 기다려(아무입력이 입력될때까지)\n",
    "cv2.destroyAllWindows   # 창 닫음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 이미지에 모자이크 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#이미지 로드\n",
    "image_1 = cv2.imread(\"people.jpg\")\n",
    "\n",
    "# 얼굴 검출기 로드\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 얼굴 감지\n",
    "faces = face_cascade.detectMultiScale(image_1, 1.1, 4)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image_1, (x,y), (x+w, y+h), (255,0,0), 2)     # 네모칸 그리기\n",
    "    print(x,y,w,h)\n",
    "    face = image_1[y:y+h, x:x+w]\n",
    "    small_face = cv2.resize(face, (16,16), interpolation=cv2.INTER_LINEAR)\n",
    "    mozaic_face = cv2.resize(small_face, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "    image_1[y:y+h, x:x+w] = mozaic_face\n",
    "\n",
    "cv2.imshow(\"Image\", image_1)    # Image 라는 이름으로 image_1 이미지 보여줌\n",
    "cv2.waitKey(0)  # 기다려(아무입력이 입력될때까지)\n",
    "cv2.destroyAllWindows   # 창 닫음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그라디오로 구현하기\n",
    "* Gradio에서 이미지를 가져오면 일반적으로 RGB 형식으로 전달됩니다. 하지만 cv2.imread()를 사용하면 OpenCV가 이미지를 자동으로 BGR 형식으로 읽어들이기 때문에, 별도로 RGB2BGR 변환을 추가로 해줄 필요가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "# 얼굴 검출기 로드\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\"\"\"\n",
    "\"OpenCV는 BGR 형식이므로 그라디오에서 받아온 RGB를 BGR로 변환 해서 처리하기\"\n",
    "\n",
    "def detect_and_mosaic(image):\n",
    "  \n",
    "    # OpenCV는 BGR 형식이므로 그라디오에서 받아온 RGB를 BGR로 변환\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 얼굴 감지\n",
    "    faces = face_cascade.detectMultiScale(image_bgr, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "    # 감지된 얼굴에 모자이크 적용\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        #바운딩 박스 그리기\n",
    "        cv2.rectangle(image_bgr, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "\n",
    "        #모자이크 적용\n",
    "        face = image_bgr[y:y+h, x:x+w]\n",
    "        small_face = cv2.resize(face, (16, 16), interpolation=cv2.INTER_LINEAR)  # 축소\n",
    "        mozaic_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)  # 확대 (모자이크 효과)\n",
    "        image_bgr[y:y+h, x:x+w] = mozaic_face  # 원본 이미지에 적용\n",
    "\n",
    "    # BGR을 다시 그라디오에서 출력할 수 있게 RGB로 변환\n",
    "    result_image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return result_image\n",
    "\"\"\"\n",
    "def detect_and_mosaic(image_path):\n",
    "    \n",
    "    # 이미지 불러오기 (cv2.imread는 기본적으로 BGR 형식)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # 얼굴 감지\n",
    "    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "    # 감지된 얼굴에 모자이크 적용\n",
    "    for (x, y, w, h) in faces:\n",
    "        # 바운딩 박스 그리기\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # 모자이크 적용\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        small_face = cv2.resize(face, (16, 16), interpolation=cv2.INTER_LINEAR)  # 축소\n",
    "        mozaic_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)  # 확대 (모자이크 효과)\n",
    "        image[y:y+h, x:x+w] = mozaic_face  # 원본 이미지에 적용\n",
    "\n",
    "    result_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return result_image\n",
    "\n",
    "\"\"\"\n",
    "\"OpenCV는 BGR 형식이므로 그라디오에서 받아온 RGB를 BGR로 변환 해서 처리한거 그라디오로 구현할 때\"\n",
    "\n",
    "Gradio 인터페이스 설정\n",
    "iface = gr.Interface(\n",
    "    fn=detect_and_mosaic,\n",
    "    inputs=gr.Image(type=\"numpy\"),  # 이미지 입력 (NumPy 배열)\n",
    "    outputs=gr.Image(type=\"numpy\"),  # 이미지 출력 (NumPy 배열)\n",
    "    title=\"얼굴 모자이크 처리기 🎭\",\n",
    "    description=\"업로드한 이미지에서 얼굴을 감지하고 자동으로 모자이크를 적용합니다.\"\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=detect_and_mosaic,\n",
    "    inputs=gr.Image(type=\"filepath\"),  # 파일 경로 입력\n",
    "    outputs=\"image\",  # 이미지 출력\n",
    "    title=\"얼굴 모자이크 처리기 🎭\",\n",
    "    description=\"업로드한 이미지에서 얼굴을 감지하고 자동으로 모자이크를 적용합니다.\"\n",
    ")\n",
    "\n",
    "# 실행\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌  비디오로(실시간) 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "camera_divice = cv2.VideoCapture(0)\n",
    "\n",
    "while True:                 # 계속해서 비디오 장치사용(라이브)\n",
    "    ret, frame = camera_divice.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"testimage\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera_divice.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 비디오(실시간)에 모자이크 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "camera_divice = cv2.VideoCapture(0)\n",
    "\n",
    "while True:   # 계속해서 비디오 장치사용(라이브)\n",
    "    ret, frame = camera_divice.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)     # 네모칸 그리기\n",
    "        # print(x,y,w,h)\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        small_face = cv2.resize(face, (16,16), interpolation=cv2.INTER_LINEAR)\n",
    "        mozaic_face = cv2.resize(small_face, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "        frame[y:y+h, x:x+w] = mozaic_face\n",
    "        cv2.imshow(\"Image\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera_divice.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI ComputerVision Face + OpenCV Mosaic 그라디오 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 얼굴 감지 중: /private/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/gradio/94e94d90eaa7f84788e83385b9cae604a0064187149ac80279d738cc20160079/people.jpg\n",
      "🔍 얼굴 감지 중: /private/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/gradio/94e94d90eaa7f84788e83385b9cae604a0064187149ac80279d738cc20160079/people.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gradio as gr\n",
    "from azure.ai.vision.face import FaceClient\n",
    "from azure.ai.vision.face.models import (\n",
    "    FaceDetectionModel,\n",
    "    FaceRecognitionModel,\n",
    "    FaceAttributeTypeDetection03\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# 🔐 Azure AI Computer Vision 자격 증명 입력 / ai sevice 리소스 입력해야함\n",
    "cog_key = \"\"\n",
    "cog_endpoint = \"\"\n",
    "\n",
    "# ✅ Azure Face Client 초기화\n",
    "face_client = FaceClient(endpoint=cog_endpoint, credential=AzureKeyCredential(cog_key))\n",
    "\n",
    "def detect_faces_and_mosaic(image_path):    # 얼굴 감지 및 모자이크 처리 함수\n",
    "\n",
    "    print(\"🔍 얼굴 감지 중:\", image_path)\n",
    "\n",
    "    # AI ComputerVision 얼굴 감지 요청\n",
    "    with open(image_path, \"rb\") as image_data:\n",
    "        detected_faces = face_client.detect(\n",
    "            image_content=image_data.read(),\n",
    "            detection_model=FaceDetectionModel.DETECTION03,\n",
    "            recognition_model=FaceRecognitionModel.RECOGNITION04,\n",
    "            return_face_id=False,\n",
    "            return_face_attributes=[\n",
    "                FaceAttributeTypeDetection03.HEAD_POSE,\n",
    "                FaceAttributeTypeDetection03.BLUR,\n",
    "                FaceAttributeTypeDetection03.MASK\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # 얼굴 없을 경우 원본 반환\n",
    "    if not detected_faces:\n",
    "        print(\"🚫 얼굴이 감지되지 않았습니다.\")\n",
    "        return cv2.imread(image_path)\n",
    "\n",
    "    # 이미지 로드\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # 얼굴마다 모자이크 처리 및 정보 출력\n",
    "    for i, face in enumerate(detected_faces):\n",
    "        \n",
    "        r = face.face_rectangle\n",
    "\n",
    "        x, y, w, h = r.left, r.top, r.width, r.height\n",
    "\n",
    "        # 모자이크 처리\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        small = cv2.resize(roi, (16, 16), interpolation=cv2.INTER_LINEAR)\n",
    "        mosaic = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "        image[y:y+h, x:x+w] = mosaic\n",
    "\n",
    "        # 얼굴 정보 시각화\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"Face {i+1}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # BGR → RGB 변환 (Gradio 출력용)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def detect_and_mosaic(image_path):\n",
    "\n",
    "    #haarcascades 얼굴인식 모델불러오기\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # 이미지 불러오기 (cv2.imread는 기본적으로 BGR 형식)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # 얼굴 감지\n",
    "    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "    # 감지된 얼굴에 모자이크 적용\n",
    "    for (x, y, w, h) in faces:\n",
    "        # 바운딩 박스 그리기\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # 모자이크 적용\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        small_face = cv2.resize(face, (16, 16), interpolation=cv2.INTER_LINEAR)  # 축소\n",
    "        mozaic_face = cv2.resize(small_face, (w, h), interpolation=cv2.INTER_NEAREST)  # 확대 (모자이크 효과)\n",
    "        image[y:y+h, x:x+w] = mozaic_face  # 원본 이미지에 적용\n",
    "\n",
    "    result_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return result_image\n",
    "\n",
    "# Gradio UI 구성\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 🖼️ Azure 얼굴 감지 및 모자이크 처리\")\n",
    "    gr.Markdown(\"이미지를 업로드하면 Azure Face API를 사용해 얼굴을 감지하고 자동으로 모자이크를 적용합니다.\")\n",
    "\n",
    "    with gr.Tab(\"Azure AI ComputerVision Face + OpenCV Mosaic\"):\n",
    "        with gr.Row():\n",
    "            input_image = gr.Image(type=\"filepath\", label=\"📤 이미지 업로드\")\n",
    "            output_image = gr.Image(label=\"📥 처리 결과\")\n",
    "\n",
    "        run_button = gr.Button(\"🧠 얼굴 분석 실행\")\n",
    "        run_button.click(fn=detect_faces_and_mosaic, inputs=input_image, outputs=output_image)\n",
    "        input_image.change(fn=detect_faces_and_mosaic, inputs=input_image, outputs=output_image)\n",
    "\n",
    "    with gr.Tab(\"only-OpenCV Mosaic\"):    \n",
    "        with gr.Row():\n",
    "            input_image = gr.Image(type=\"filepath\", label=\"📤 이미지 업로드\")\n",
    "            output_image = gr.Image(label=\"📥 처리 결과\")\n",
    "\n",
    "        run_button = gr.Button(\"🧠 얼굴 분석 실행\")\n",
    "        run_button.click(fn=detect_and_mosaic, inputs=input_image, outputs=output_image)\n",
    "        input_image.change(fn=detect_and_mosaic, inputs=input_image, outputs=output_image)\n",
    "\n",
    "# 앱 실행\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
