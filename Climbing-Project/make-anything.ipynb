{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ì‚¬ìš©ìƒì˜ ì£¼ì˜ì‚¬í•­]ì‚¬ìš© ì „ì—ëŠ” ë°˜ë“œì‹œ ì„ì‹  ì¤‘ì´ ì•„ë‹˜ì„ í™•ì¸í•œ í›„ì— ì‚¬ìš©í•  ê²ƒ. ì„ì‹ ì´ˆê¸° ë™ì•ˆì— ì´ ì•½ì˜1. ê²½ê³  : ì´ ì•½ì— í•¨ìœ ë˜ì–´ ìˆëŠ” ì¸ê³µê°ë¯¸ì œ ì•„ìŠ¤íŒŒíƒì€ ì²´ë‚´ì—ì„œ ë¶„í•´ë˜ì–´ í˜ë‹ì•Œë¼ë‹Œíˆ¬ì—¬ë¥¼ í”¼í•˜ê¸° ìœ„í•´ì„œ ê°€ì„(ì„ì‹ ê°€ëŠ¥ì„± ìˆëŠ”)ì—°ë ¹ì˜ ì—¬ì„±ì€ ìƒë¦¬ ì²« 10ì¼ ë™ì•ˆ ë˜ëŠ” ì„ì‹ ìœ¼ë¡œ ëŒ€ì‚¬ë˜ë¯€ë¡œ, í˜ë‹ì•Œë¼ë‹Œì˜ ì„­ì·¨ë¥¼ ê·œì œí•  í•„ìš”ê°€ ìˆëŠ” ìœ ì „ì„±ì§ˆí™˜ì¸ í˜ë‹ì¼€í†¤ë‡¨ì¦í…ŒìŠ¤íŠ¸ì—ì„œ ìŒì„±ì´ ë‚˜íƒ€ë‚œ í›„ì— ì¹˜ë£Œë¥¼ ì‹œì‘í•  ê²ƒ. 2) ë™ë¬¼ ìƒì‹ ì—°êµ¬ ê²°ê³¼ ì´ ì•½ì€ ì„ë¶€ê°€í™˜ìì—ëŠ” íˆ¬ì—¬í•˜ì§€ ë§ ê²ƒ. â€» 1ì¼í—ˆìš©ëŸ‰ì œí•œ : ì•„ìŠ¤íŒŒíƒ í•¨ëŸ‰ì„ WHOê¶Œì¥ëŸ‰ (40mgíˆ¬ì—¬í•˜ì˜€ì„ ë•Œ íƒœì•„ ì†ìƒì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. ë«íŠ¸ì™€ í† ë¼ì—ì„œ ê¸°ê´€ í˜•ì„± ê¸°ê°„ ë™ì•ˆ íˆ¬ì—¬ ì‹œ/kg/1ì¼) ì´í•˜ë¡œ ì¡°ì •(ê°€ëŠ¥í•œí•œ ìµœì†ŒëŸ‰ ì‚¬ìš©)í•  ê²ƒ. 60kgì„±ì¸: 1ì¼ ìµœëŒ€ë³µìš©ëŸ‰ 2.4g(ì „ì²´ ì‹ ì²´ í‘œë©´ì ì— ëŒ€í•˜ì—¬ ì •ëŸ‰í™”ëœ ì‚¬ëŒ ê¶Œì¥ ìš©ëŸ‰ì˜ ì•½ 0.1-0.6 ë°°ë¥¼ ê²½êµ¬ íˆ¬ì—¬ ë°°ì•„2. ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ëŒì€ ì´ ì•½ì„ ë³µìš©(ì‚¬ìš©)í•˜ì§€ ë§ ê²ƒ. 1) ì´ ì•½ ë° ì´ ì•½ì˜ êµ¬ì„±ì„±ë¶„ì–´ë…ì„± ë° ê³¨ê²© ë³€ì´ê°€ ë³´ê³ ë˜ì—ˆë‹¤. íƒœì•„ì˜ ì ì¬ì  ìœ„í—˜ì„ ê³ ë ¤í•˜ì—¬ ì„ì‹ ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê³¼ë¯¼ë°˜ì‘ í™˜ì 2) ì„ë¶€ ë° ì„ì‹ í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì—¬ì„± ë° ìˆ˜ìœ ë¶€ 3) 2ì„¸ ë¯¸ë§Œì˜ì„±ì€ ì´ ì•½ì˜ íˆ¬ì—¬ê¸°ê°„ ë™ì•ˆ ë° ë§ˆì§€ë§‰ íˆ¬ì—¬ ì´í›„ 3ì¼ ê¹Œì§€ íš¨ê³¼ì ì¸ í”¼ì„ ë°©ë²•ì„ì†Œì•„ 4) ì´ ì•½ì€ ìœ ë‹¹[ì –ë‹¹]ì„ í•¨ìœ í•˜ê³  ìˆìœ¼ë¯€ë¡œ, ê°ˆë½í† ì˜¤ìŠ¤ë¶ˆë‚´ì„±(galactose intolerance),ì‚¬ìš©í•œë‹¤. 3) ì„ìƒê²€ì‚¬ì¹˜ì—ì˜ ì˜í–¥ : ë•Œë•Œë¡œ ê°€ì—­ì ì¸(íšŒë³µ ê°€ëŠ¥í•œ) ë°±í˜ˆêµ¬ ìˆ˜ì˜ ê°ì†Œë¥¼Lapp ìœ ë‹¹[ì –ë‹¹]ë¶„í•´íš¨ì†Œ ê²°í•ì¦(Lapp lactase deficiency) ë˜ëŠ” í¬ë„ë‹¹-ê°ˆë½í† ì˜¤ìŠ¤ìœ ë°œí•  ìˆ˜ ìˆê³ , ê²½ì¦ ë‚´ì§€ ì¤‘ë“±ë„ì˜ ê°„íš¨ì†Œì¹˜ê°€ ì¦ê°€í•  ìˆ˜ ìˆë‹¤. ì²˜ë°© ì‹œ ë²”í˜ˆêµ¬(ì „ì²´í˜ˆêµ¬)í¡ìˆ˜ì¥ì• (glucose-galactose malabsorption) ë“±ì˜ ìœ ì „ì ì¸ ë¬¸ì œê°€ ìˆëŠ” í™˜ìê°ì†Œì¦ì„ ìœ ë°œí• ì†Œì¦ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. 4) í”„ë¼ì§€ê´€í…”ì´ ì•Œë²¤ë‹¤ì¡¸ í™œì„± ëŒ€ì‚¬ì²´ì˜ í˜ˆì¥ë†ë„ë¥¼ ì¦ê°€ì—ê²ŒëŠ” íˆ¬ì—¬í•˜ë©´ ì•ˆ ëœë‹¤. 3. ì´ ì•½ì„ ë³µìš©(ì‚¬ìš©)í•˜ëŠ” ë™ì•ˆ ë‹¤ìŒì˜ ì•½ì„ ë³µìš©(ì‚¬ìš©)í•˜ì§€ì‹œí‚¨ë‹¤ëŠ” ë³´ê³ ê°€ ìˆë‹¤. 5) ê³¼ëŸ‰íˆ¬ì—¬ í–ˆì„ ê²½ìš° ëŒ€ì¦ìš”ë²• (ì¦ìƒë³„ë¡œ ì¹˜ë£Œí•˜ëŠ” ë°©ë²•) (ìœ„ì„¸ì²™)ë§ ê²ƒ. 1) í…Œì˜¤í•„ë¦° : í…Œì˜¤í•„ë¦°ì˜ ëŒ€ì‚¬ë¥¼ ì–µì œí•  ìˆ˜ ìˆë‹¤. 2) ì‹œë©”í‹°ë”˜, í”„ë¼ì§€ê´€í…”,ë° ì¼ë°˜ì ì¸ ì§€ì§€ ìš”ë²•ì„ ì‚¬ìš©í•œë‹¤. 6) ì¡°ì¶© (taeniasis) ê°ì—¼ì´ ë†’ì€ ì§€ì—­ì—ì„œ ê¸°ì¡´ì˜ë±ì‚¬ë©”íƒ€ì† : ì•Œë²¤ë‹¤ì¡¸ì˜ í˜ˆì¥ë†ë„ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤. 3) ë¦¬í† ë‚˜ë¹„ì–´, í˜ë‹ˆí† ì¸, ì¹´ë¥´ë°”ë‡Œìœ ë‚­ë¯¸ì¶©ì¦(neurocysticercosis)ì— ëŒ€í•œ ì•Œë²¤ë‹¤ì¡¸ ì¹˜ë£Œê°€ ì´ë£¨ì–´ì§„ ê²½ìš°, ë‡Œë‚´ ê¸°ìƒì¶©ë§ˆì œí•€, í˜ë…¸ë°”ë¥´ë¹„íƒˆ : ì•Œë²¤ë‹¤ì¡¸ì˜ í˜ˆì¥ ë†ë„ë¥¼ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆë‹¤. 4. ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ëŒì€ì‚¬ë©¸ì— ì˜í•œ ì—¼ì¦ ë°˜ì‘ìœ¼ë¡œ, ë°œì‘, ë‘ê°œë‚´ì••ìƒìŠ¹, ì†Œì¦ìƒê³¼ ê°™ì€ ì‹ ê²½í•™ì  ì¦ìƒë“¤ì´ë‚˜íƒ€ë‚  ìˆ˜ ìˆìœ¼ë©°, ì¦ìƒë“¤ì€ ì¹˜ë£Œì§í›„ ë°œìƒë  ìˆ˜ ìˆë‹¤. ì´ ì•½ì„ ë³µìš©í•œ í›„ ì´ëŸ¬í•œ ì¦ìƒë“¤ì„ì´ ì•½ì„ ë³µìš©í•˜ê¸° ì „ì— ì˜ì‚¬, ì¹˜ê³¼ì˜ì‚¬, ì•½ì‚¬ì™€ ìƒì˜í•  ê²ƒ. 1) ê°„ì¥ì•  í™˜ì 2) ì‹ ì¥ì•  ë³´ì¸ í™˜ìë“¤ì€ ë°”ë¡œ ì˜ë£Œì§„ê³¼ ìƒì˜í•œë‹¤. 7. ì €ì¥ìƒì˜ ì£¼ì˜ì‚¬í•­ 1) ì–´ë¦°ì´ì˜ ì†ì´ ë‹¿ì§€(ì‹ ì¥ì¥ì• ) í™˜ì 3) ì´ ì•½ì€ í™©ìƒ‰5í˜¸(ì„ ì…‹ì˜ë¡œìš° FCF, Sunset Yellow FCF)ë¥¼ í•¨ìœ í•˜ê³ ìˆìœ¼ë¯€ë¡œ ì´ ì„±ë¶„ì— ê³¼ë¯¼í•˜ê±°ë‚˜ ì•Œë ˆë¥´ê¸° ë³‘ë ¥ì´ ìˆëŠ” í™˜ìì—ëŠ” ì‹ ì¤‘íˆ íˆ¬ì—¬í•  ê²ƒ.ì•ŠëŠ” ê³³ì— ë³´ê´€í•  ê²ƒ. 2) ì§ì‚¬ì¼ê´‘ì„ í”¼í•˜ì—¬ ê±´ëƒ‰(ê±´ì¡°í•˜ê³  ì‹œì›)í•œ ê³³ì— ì‹¤ì˜¨ ë³´ê´€í•  ê²ƒ.5. ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° ì´ ì•½ì˜ ë³µìš©ì„ ì¦‰ê° ì¤‘ì§€í•˜ê³  ì˜ì‚¬, ì¹˜ê³¼ì˜ì‚¬, ì•½ì‚¬ì™€ ìƒì˜í•  ê²ƒ.3) ì˜¤ìš©(ì˜ëª»ì‚¬ìš©) Â· ë‚¨ìš©ì„ í”¼í•˜ê³ , í’ˆì§ˆì„ ë³´í˜¸ Â· ìœ ì§€í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ìš©ê¸°ì— ë„£ì§€ ë§ ê²ƒ.ìƒë‹´ ì‹œ ê°€ëŠ¥í•œ ì´ ì²¨ë¶€ë¬¸ì„œë¥¼ ì†Œì§€í•  ê²ƒ. 1) í”¼ë¶€ì ë§‰ì•ˆì¦í›„êµ°(ìŠ¤í‹°ë¸ìŠ¤-ì¡´ìŠ¤ì¦í›„êµ°)â€» ë§Œì•½ êµ¬ì… ë‹¹ì‹œ ì‚¬ìš©(ìœ íš¨)ì‚¬ìš©(ìœ íš¨)ê¸°í•œì´ ê²½ê³¼ë˜ì—ˆê±°ë‚˜ ë³€ì§ˆ, ë³€íŒ¨ ë˜ëŠ” ì˜¤ì—¼ë˜ê±°ë‚˜ ì†ìƒëœ ì œí’ˆì€ êµ¬ì…ì²˜ë¥¼ í†µí•˜ì—¬ë‹¤í˜•í™ë°˜(ì—¬ëŸ¬ ëª¨ì–‘ì˜ ë¶‰ì€ ë°˜ì )ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° íˆ¬ì—¬ë¥¼ ì¤‘ì§€í•˜ê³  ì ì ˆí•œêµí™˜í•˜ì—¬ ë“œë¦½ë‹ˆë‹¤. ë³¸ ì œí’ˆì— ì´ìƒì´ ìˆì„ ê²½ìš° ê³µì •ê±°ë˜ìœ„ì›íšŒ ê³ ì‹œ ì†Œë¹„ìë¶„ìŸí•´ê²°ê¸°ì¤€ì— ì˜ê±° êµí™˜ ë˜ëŠ” ë³´ìƒ ë°›ì„ì²˜ì¹˜ë¥¼ ì‹¤ì‹œí•œë‹¤. 2) êµ¬ì—­, êµ¬í† , ì†ì“°ë¦¼, ì„¤ì‚¬, ìƒë³µë¶€ ë˜ëŠ” ë³µë¶€(ë°°ë¶€ë¶„) í†µì¦ ë“±ì˜ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€» ë³¸ ë¬¸ì•ˆ ì‘ì„±ì¼ì ì´í›„ ë³€ê²½ëœ ë‚´ìš©ì€ ë‹¹ì‹œë‚œìœ¼ë©´ ë‚´ìš©ì€ ê³µì‚¬ í™ˆí˜ì´ì§€ www.boryung.co.kr ë˜ëŠ” ì†Œë¹„ììƒë‹´ì‹¤ì—ì„œìœ„ì¥ê´€ ì¥ì•  ë˜ëŠ” ë‘í†µ ë° ì–´ì§€ëŸ¼ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. 3) ë“œë¬¼ê²Œ ë°œì—´, ì „ì‹  ë°œì (ì¶©í˜ˆë˜ì–´í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€» ì˜ì•½í’ˆ ìš©ì–´ ì„¤ëª… ë° ê¸°íƒ€ ìì„¸í•œ ì˜ì•½í’ˆì •ë³´ëŠ” ì˜ì•½í’ˆí†µí•©ì •ë³´ì‹œìŠ¤í…œ (nedrug.mos.go.kr)ì„ë¶‰ì–´ì§), ë°œì§„, ê°€ë ¤ì›€, ë‘ë“œëŸ¬ê¸° ë“±ì˜ ê³¼ë¯¼ë°˜ì‘ì´ ë‚˜íƒ€ë‚¬ë‹¤ëŠ” ë³´ê³ ê°€ ìˆë‹¤. 4) ê°€ì—­ì ì¸ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. â€» ì˜ì•½í’ˆ ë¶€ì‘ìš© í”¼í•´êµ¬ì œ ìƒë‹´, ì‹ ì²­ : í•œêµ­ì˜ì•½í’ˆë‹¤ë‹ˆë‹ˆèˆŒì•ˆì „ê´€ë¦¬ì›(14-330/1644-6223)(íšŒë³µ ê°€ëŠ¥í•œ) íƒˆëª¨ì¦ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. 6. ê¸°íƒ€ ì´ ì•½ì˜ ë³µìš© ì‹œ ì£¼ì˜í•  ì‚¬í•­ 1) ì´ ì•½â€» ì‚¬ìš©(ìœ íš¨) ê¸°í•œì´ ê²½ê³¼í•œ ì œí’ˆì€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹œê¸° ë°”ëë‹ˆë‹¤.ë¬¸ì•ˆ ì‘ì„±ì¼ì : 2022ë…„ 4ì›” 20ì¼'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "ocr_endpoint = \"\"\n",
    "ocr_key = ''\n",
    "\n",
    "\n",
    "file_path = \"../Azure AI Vision/images/IMG_4692.jpg\"\n",
    "\n",
    "# Set the values of your computer vision endpoint and computer vision key as environment variables:\n",
    "try:\n",
    "    endpoint = ocr_endpoint\n",
    "    key = ocr_key\n",
    "except KeyError:\n",
    "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()\n",
    "\n",
    "def image_OCR(input_image):\n",
    "    read_text = []\n",
    "    # Create an Image Analysis client\n",
    "    client = ImageAnalysisClient(\n",
    "        endpoint=ocr_endpoint,\n",
    "        credential=AzureKeyCredential(ocr_key)\n",
    "    )\n",
    "\n",
    "    visual_features=[\n",
    "        VisualFeatures.READ\n",
    "        ]\n",
    "\n",
    "    if not \"https://\" in input_image or not \"http://\" in input_image:\n",
    "    # Load image to analyze into a 'bytes' object\n",
    "        with open(input_image, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "\n",
    "            # Get a caption for the image. This will be a synchronously (blocking) call. / ìš”ì²­í•œê±° ì‘ë‹µë°›ê¸°\n",
    "            result = client.analyze(\n",
    "                image_data=image_data,\n",
    "                visual_features=visual_features,\n",
    "                gender_neutral_caption=True,  # Optional (default is False)\n",
    "            )\n",
    "    else:\n",
    "        # Get a caption for the image. This will be a synchronously (blocking) call. / ìš”ì²­í•œê±° ì‘ë‹µë°›ê¸°\n",
    "        result = client.analyze_from_url(\n",
    "            image_url=input_image,\n",
    "            visual_features=visual_features,\n",
    "            gender_neutral_caption=True,  # Optional (default is False)\n",
    "        )\n",
    "\n",
    "    # Print text (OCR) analysis results to the console\n",
    "    # print(\" Read:\")\n",
    "    if result.read is not None:\n",
    "        for line in result.read.blocks[0].lines:\n",
    "            # print(line.text)\n",
    "            read_text.append(line.text)\n",
    "        return \"\".join(read_text)\n",
    "\n",
    "image_OCR(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary extracted: \n",
      "The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. This feature is provided as an API for developers. Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations.\n",
      "Summary Abstractive: \n",
      "The described API leverages advanced natural language processing (NLP) to perform extractive summarization, identifying pivotal sentences that encapsulate the core message of an unstructured text. Developers can integrate this functionality into their applications to access essential insights from large volumes of text data. The system supports multiple languages by utilizing pretrained multilingual transformer models, emphasizing the shared linguistic characteristics to enhance model performance. This approach, grounded in transfer learning, aims to deliver high-quality summaries efficiently, making it a versatile tool for developers seeking to create intelligent solutions that can process and summarize content across different languages. The underlying technology not only facilitates summarization but also exemplifies the potential of transfer learning in improving NLP applications. The focus on multilingual capabilities highlights the API's global applicability for summarizing documents in diverse languages.\n"
     ]
    }
   ],
   "source": [
    "# This example requires environment variables named \"LANGUAGE_KEY\" and \"LANGUAGE_ENDPOINT\"\n",
    "summery_key = \"\"\n",
    "summery_endpoint = \"\"\n",
    "\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "\n",
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(summery_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=summery_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Example method for summarizing text\n",
    "def sample_extractive_summarization(client):\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.textanalytics import (\n",
    "        TextAnalyticsClient,\n",
    "        ExtractiveSummaryAction,\n",
    "        AbstractiveSummaryAction\n",
    "    ) \n",
    "\n",
    "    document = [\n",
    "        \"The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. \"\n",
    "        \"These sentences collectively convey the main idea of the document. This feature is provided as an API for developers. \" \n",
    "        \"They can use it to build intelligent solutions based on the relevant information extracted to support various use cases. \"\n",
    "        \"Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations. \"\n",
    "        \"It draws its strength from transfer learning across monolingual and harness the shared nature of languages to produce models of improved quality and efficiency. \"\n",
    "    ]\n",
    "\n",
    "    poller_1 = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[\n",
    "            ExtractiveSummaryAction(max_sentence_count=4)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    poller_2 = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[\n",
    "            AbstractiveSummaryAction()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    document_results_1 = poller_1.result()\n",
    "    for result in document_results_1:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            ))\n",
    "        else:\n",
    "            print(\"Summary extracted: \\n{}\".format(\n",
    "                \" \".join([sentence.text for sentence in extract_summary_result.sentences]))\n",
    "            )\n",
    "\n",
    "    document_results_2 = poller_2.result()\n",
    "    \n",
    "    for result in document_results_2:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            ))\n",
    "        else:\n",
    "            print(\"Summary Abstractive: \\n{}\".format(\n",
    "                \" \".join([sentence.text for sentence in extract_summary_result.summaries]))\n",
    "            )\n",
    "\n",
    "sample_extractive_summarization(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í˜¼í•©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ì‚¬ìš©ìƒì˜ ì£¼ì˜ì‚¬í•­]ì‚¬ìš© ì „ì—ëŠ” ë°˜ë“œì‹œ ì„ì‹  ì¤‘ì´ ì•„ë‹˜ì„ í™•ì¸í•œ í›„ì— ì‚¬ìš©í•  ê²ƒ. ì„ì‹ ì´ˆê¸° ë™ì•ˆì— ì´ ì•½ì˜1. ê²½ê³  : ì´ ì•½ì— í•¨ìœ ë˜ì–´ ìˆëŠ” ì¸ê³µê°ë¯¸ì œ ì•„ìŠ¤íŒŒíƒì€ ì²´ë‚´ì—ì„œ ë¶„í•´ë˜ì–´ í˜ë‹ì•Œë¼ë‹Œíˆ¬ì—¬ë¥¼ í”¼í•˜ê¸° ìœ„í•´ì„œ ê°€ì„(ì„ì‹ ê°€ëŠ¥ì„± ìˆëŠ”)ì—°ë ¹ì˜ ì—¬ì„±ì€ ìƒë¦¬ ì²« 10ì¼ ë™ì•ˆ ë˜ëŠ” ì„ì‹ ìœ¼ë¡œ ëŒ€ì‚¬ë˜ë¯€ë¡œ, í˜ë‹ì•Œë¼ë‹Œì˜ ì„­ì·¨ë¥¼ ê·œì œí•  í•„ìš”ê°€ ìˆëŠ” ìœ ì „ì„±ì§ˆí™˜ì¸ í˜ë‹ì¼€í†¤ë‡¨ì¦í…ŒìŠ¤íŠ¸ì—ì„œ ìŒì„±ì´ ë‚˜íƒ€ë‚œ í›„ì— ì¹˜ë£Œë¥¼ ì‹œì‘í•  ê²ƒ. 2) ë™ë¬¼ ìƒì‹ ì—°êµ¬ ê²°ê³¼ ì´ ì•½ì€ ì„ë¶€ê°€í™˜ìì—ëŠ” íˆ¬ì—¬í•˜ì§€ ë§ ê²ƒ. â€» 1ì¼í—ˆìš©ëŸ‰ì œí•œ : ì•„ìŠ¤íŒŒíƒ í•¨ëŸ‰ì„ WHOê¶Œì¥ëŸ‰ (40mgíˆ¬ì—¬í•˜ì˜€ì„ ë•Œ íƒœì•„ ì†ìƒì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. ë«íŠ¸ì™€ í† ë¼ì—ì„œ ê¸°ê´€ í˜•ì„± ê¸°ê°„ ë™ì•ˆ íˆ¬ì—¬ ì‹œ/kg/1ì¼) ì´í•˜ë¡œ ì¡°ì •(ê°€ëŠ¥í•œí•œ ìµœì†ŒëŸ‰ ì‚¬ìš©)í•  ê²ƒ. 60kgì„±ì¸: 1ì¼ ìµœëŒ€ë³µìš©ëŸ‰ 2.4g(ì „ì²´ ì‹ ì²´ í‘œë©´ì ì— ëŒ€í•˜ì—¬ ì •ëŸ‰í™”ëœ ì‚¬ëŒ ê¶Œì¥ ìš©ëŸ‰ì˜ ì•½ 0.1-0.6 ë°°ë¥¼ ê²½êµ¬ íˆ¬ì—¬ ë°°ì•„2. ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ëŒì€ ì´ ì•½ì„ ë³µìš©(ì‚¬ìš©)í•˜ì§€ ë§ ê²ƒ. 1) ì´ ì•½ ë° ì´ ì•½ì˜ êµ¬ì„±ì„±ë¶„ì–´ë…ì„± ë° ê³¨ê²© ë³€ì´ê°€ ë³´ê³ ë˜ì—ˆë‹¤. íƒœì•„ì˜ ì ì¬ì  ìœ„í—˜ì„ ê³ ë ¤í•˜ì—¬ ì„ì‹ ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê³¼ë¯¼ë°˜ì‘ í™˜ì 2) ì„ë¶€ ë° ì„ì‹ í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì—¬ì„± ë° ìˆ˜ìœ ë¶€ 3) 2ì„¸ ë¯¸ë§Œì˜ì„±ì€ ì´ ì•½ì˜ íˆ¬ì—¬ê¸°ê°„ ë™ì•ˆ ë° ë§ˆì§€ë§‰ íˆ¬ì—¬ ì´í›„ 3ì¼ ê¹Œì§€ íš¨ê³¼ì ì¸ í”¼ì„ ë°©ë²•ì„ì†Œì•„ 4) ì´ ì•½ì€ ìœ ë‹¹[ì –ë‹¹]ì„ í•¨ìœ í•˜ê³  ìˆìœ¼ë¯€ë¡œ, ê°ˆë½í† ì˜¤ìŠ¤ë¶ˆë‚´ì„±(galactose intolerance),ì‚¬ìš©í•œë‹¤. 3) ì„ìƒê²€ì‚¬ì¹˜ì—ì˜ ì˜í–¥ : ë•Œë•Œë¡œ ê°€ì—­ì ì¸(íšŒë³µ ê°€ëŠ¥í•œ) ë°±í˜ˆêµ¬ ìˆ˜ì˜ ê°ì†Œë¥¼Lapp ìœ ë‹¹[ì –ë‹¹]ë¶„í•´íš¨ì†Œ ê²°í•ì¦(Lapp lactase deficiency) ë˜ëŠ” í¬ë„ë‹¹-ê°ˆë½í† ì˜¤ìŠ¤ìœ ë°œí•  ìˆ˜ ìˆê³ , ê²½ì¦ ë‚´ì§€ ì¤‘ë“±ë„ì˜ ê°„íš¨ì†Œì¹˜ê°€ ì¦ê°€í•  ìˆ˜ ìˆë‹¤. ì²˜ë°© ì‹œ ë²”í˜ˆêµ¬(ì „ì²´í˜ˆêµ¬)í¡ìˆ˜ì¥ì• (glucose-galactose malabsorption) ë“±ì˜ ìœ ì „ì ì¸ ë¬¸ì œê°€ ìˆëŠ” í™˜ìê°ì†Œì¦ì„ ìœ ë°œí• ì†Œì¦ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. 4) í”„ë¼ì§€ê´€í…”ì´ ì•Œë²¤ë‹¤ì¡¸ í™œì„± ëŒ€ì‚¬ì²´ì˜ í˜ˆì¥ë†ë„ë¥¼ ì¦ê°€ì—ê²ŒëŠ” íˆ¬ì—¬í•˜ë©´ ì•ˆ ëœë‹¤. 3. ì´ ì•½ì„ ë³µìš©(ì‚¬ìš©)í•˜ëŠ” ë™ì•ˆ ë‹¤ìŒì˜ ì•½ì„ ë³µìš©(ì‚¬ìš©)í•˜ì§€ì‹œí‚¨ë‹¤ëŠ” ë³´ê³ ê°€ ìˆë‹¤. 5) ê³¼ëŸ‰íˆ¬ì—¬ í–ˆì„ ê²½ìš° ëŒ€ì¦ìš”ë²• (ì¦ìƒë³„ë¡œ ì¹˜ë£Œí•˜ëŠ” ë°©ë²•) (ìœ„ì„¸ì²™)ë§ ê²ƒ. 1) í…Œì˜¤í•„ë¦° : í…Œì˜¤í•„ë¦°ì˜ ëŒ€ì‚¬ë¥¼ ì–µì œí•  ìˆ˜ ìˆë‹¤. 2) ì‹œë©”í‹°ë”˜, í”„ë¼ì§€ê´€í…”,ë° ì¼ë°˜ì ì¸ ì§€ì§€ ìš”ë²•ì„ ì‚¬ìš©í•œë‹¤. 6) ì¡°ì¶© (taeniasis) ê°ì—¼ì´ ë†’ì€ ì§€ì—­ì—ì„œ ê¸°ì¡´ì˜ë±ì‚¬ë©”íƒ€ì† : ì•Œë²¤ë‹¤ì¡¸ì˜ í˜ˆì¥ë†ë„ë¥¼ ì¦ê°€ì‹œí‚¨ë‹¤. 3) ë¦¬í† ë‚˜ë¹„ì–´, í˜ë‹ˆí† ì¸, ì¹´ë¥´ë°”ë‡Œìœ ë‚­ë¯¸ì¶©ì¦(neurocysticercosis)ì— ëŒ€í•œ ì•Œë²¤ë‹¤ì¡¸ ì¹˜ë£Œê°€ ì´ë£¨ì–´ì§„ ê²½ìš°, ë‡Œë‚´ ê¸°ìƒì¶©ë§ˆì œí•€, í˜ë…¸ë°”ë¥´ë¹„íƒˆ : ì•Œë²¤ë‹¤ì¡¸ì˜ í˜ˆì¥ ë†ë„ë¥¼ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆë‹¤. 4. ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ëŒì€ì‚¬ë©¸ì— ì˜í•œ ì—¼ì¦ ë°˜ì‘ìœ¼ë¡œ, ë°œì‘, ë‘ê°œë‚´ì••ìƒìŠ¹, ì†Œì¦ìƒê³¼ ê°™ì€ ì‹ ê²½í•™ì  ì¦ìƒë“¤ì´ë‚˜íƒ€ë‚  ìˆ˜ ìˆìœ¼ë©°, ì¦ìƒë“¤ì€ ì¹˜ë£Œì§í›„ ë°œìƒë  ìˆ˜ ìˆë‹¤. ì´ ì•½ì„ ë³µìš©í•œ í›„ ì´ëŸ¬í•œ ì¦ìƒë“¤ì„ì´ ì•½ì„ ë³µìš©í•˜ê¸° ì „ì— ì˜ì‚¬, ì¹˜ê³¼ì˜ì‚¬, ì•½ì‚¬ì™€ ìƒì˜í•  ê²ƒ. 1) ê°„ì¥ì•  í™˜ì 2) ì‹ ì¥ì•  ë³´ì¸ í™˜ìë“¤ì€ ë°”ë¡œ ì˜ë£Œì§„ê³¼ ìƒì˜í•œë‹¤. 7. ì €ì¥ìƒì˜ ì£¼ì˜ì‚¬í•­ 1) ì–´ë¦°ì´ì˜ ì†ì´ ë‹¿ì§€(ì‹ ì¥ì¥ì• ) í™˜ì 3) ì´ ì•½ì€ í™©ìƒ‰5í˜¸(ì„ ì…‹ì˜ë¡œìš° FCF, Sunset Yellow FCF)ë¥¼ í•¨ìœ í•˜ê³ ìˆìœ¼ë¯€ë¡œ ì´ ì„±ë¶„ì— ê³¼ë¯¼í•˜ê±°ë‚˜ ì•Œë ˆë¥´ê¸° ë³‘ë ¥ì´ ìˆëŠ” í™˜ìì—ëŠ” ì‹ ì¤‘íˆ íˆ¬ì—¬í•  ê²ƒ.ì•ŠëŠ” ê³³ì— ë³´ê´€í•  ê²ƒ. 2) ì§ì‚¬ì¼ê´‘ì„ í”¼í•˜ì—¬ ê±´ëƒ‰(ê±´ì¡°í•˜ê³  ì‹œì›)í•œ ê³³ì— ì‹¤ì˜¨ ë³´ê´€í•  ê²ƒ.5. ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° ì´ ì•½ì˜ ë³µìš©ì„ ì¦‰ê° ì¤‘ì§€í•˜ê³  ì˜ì‚¬, ì¹˜ê³¼ì˜ì‚¬, ì•½ì‚¬ì™€ ìƒì˜í•  ê²ƒ.3) ì˜¤ìš©(ì˜ëª»ì‚¬ìš©) Â· ë‚¨ìš©ì„ í”¼í•˜ê³ , í’ˆì§ˆì„ ë³´í˜¸ Â· ìœ ì§€í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ìš©ê¸°ì— ë„£ì§€ ë§ ê²ƒ.ìƒë‹´ ì‹œ ê°€ëŠ¥í•œ ì´ ì²¨ë¶€ë¬¸ì„œë¥¼ ì†Œì§€í•  ê²ƒ. 1) í”¼ë¶€ì ë§‰ì•ˆì¦í›„êµ°(ìŠ¤í‹°ë¸ìŠ¤-ì¡´ìŠ¤ì¦í›„êµ°)â€» ë§Œì•½ êµ¬ì… ë‹¹ì‹œ ì‚¬ìš©(ìœ íš¨)ì‚¬ìš©(ìœ íš¨)ê¸°í•œì´ ê²½ê³¼ë˜ì—ˆê±°ë‚˜ ë³€ì§ˆ, ë³€íŒ¨ ë˜ëŠ” ì˜¤ì—¼ë˜ê±°ë‚˜ ì†ìƒëœ ì œí’ˆì€ êµ¬ì…ì²˜ë¥¼ í†µí•˜ì—¬ë‹¤í˜•í™ë°˜(ì—¬ëŸ¬ ëª¨ì–‘ì˜ ë¶‰ì€ ë°˜ì )ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° íˆ¬ì—¬ë¥¼ ì¤‘ì§€í•˜ê³  ì ì ˆí•œêµí™˜í•˜ì—¬ ë“œë¦½ë‹ˆë‹¤. ë³¸ ì œí’ˆì— ì´ìƒì´ ìˆì„ ê²½ìš° ê³µì •ê±°ë˜ìœ„ì›íšŒ ê³ ì‹œ ì†Œë¹„ìë¶„ìŸí•´ê²°ê¸°ì¤€ì— ì˜ê±° êµí™˜ ë˜ëŠ” ë³´ìƒ ë°›ì„ì²˜ì¹˜ë¥¼ ì‹¤ì‹œí•œë‹¤. 2) êµ¬ì—­, êµ¬í† , ì†ì“°ë¦¼, ì„¤ì‚¬, ìƒë³µë¶€ ë˜ëŠ” ë³µë¶€(ë°°ë¶€ë¶„) í†µì¦ ë“±ì˜ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€» ë³¸ ë¬¸ì•ˆ ì‘ì„±ì¼ì ì´í›„ ë³€ê²½ëœ ë‚´ìš©ì€ ë‹¹ì‹œë‚œìœ¼ë©´ ë‚´ìš©ì€ ê³µì‚¬ í™ˆí˜ì´ì§€ www.boryung.co.kr ë˜ëŠ” ì†Œë¹„ììƒë‹´ì‹¤ì—ì„œìœ„ì¥ê´€ ì¥ì•  ë˜ëŠ” ë‘í†µ ë° ì–´ì§€ëŸ¼ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. 3) ë“œë¬¼ê²Œ ë°œì—´, ì „ì‹  ë°œì (ì¶©í˜ˆë˜ì–´í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€» ì˜ì•½í’ˆ ìš©ì–´ ì„¤ëª… ë° ê¸°íƒ€ ìì„¸í•œ ì˜ì•½í’ˆì •ë³´ëŠ” ì˜ì•½í’ˆí†µí•©ì •ë³´ì‹œìŠ¤í…œ (nedrug.mos.go.kr)ì„ë¶‰ì–´ì§), ë°œì§„, ê°€ë ¤ì›€, ë‘ë“œëŸ¬ê¸° ë“±ì˜ ê³¼ë¯¼ë°˜ì‘ì´ ë‚˜íƒ€ë‚¬ë‹¤ëŠ” ë³´ê³ ê°€ ìˆë‹¤. 4) ê°€ì—­ì ì¸ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. â€» ì˜ì•½í’ˆ ë¶€ì‘ìš© í”¼í•´êµ¬ì œ ìƒë‹´, ì‹ ì²­ : í•œêµ­ì˜ì•½í’ˆë‹¤ë‹ˆë‹ˆèˆŒì•ˆì „ê´€ë¦¬ì›(14-330/1644-6223)(íšŒë³µ ê°€ëŠ¥í•œ) íƒˆëª¨ì¦ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. 6. ê¸°íƒ€ ì´ ì•½ì˜ ë³µìš© ì‹œ ì£¼ì˜í•  ì‚¬í•­ 1) ì´ ì•½â€» ì‚¬ìš©(ìœ íš¨) ê¸°í•œì´ ê²½ê³¼í•œ ì œí’ˆì€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹œê¸° ë°”ëë‹ˆë‹¤.ë¬¸ì•ˆ ì‘ì„±ì¼ì : 2022ë…„ 4ì›” 20ì¼'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import tempfile\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Azure AI services ì—”ë“œí¬ì¸íŠ¸ í‚¤ê°’í•„ìš”í•¨\n",
    "ocr_endpoint = ''\n",
    "ocr_key = ''\n",
    "\n",
    "# Language Service ì—”ë“œí¬ì¸íŠ¸ í‚¤ê°’\n",
    "summery_key = \"\"\n",
    "summery_endpoint = \"\"\n",
    "\n",
    "# AI Speech í‚¤ ì§€ì—­ \n",
    "subscription = \"\"\n",
    "region = \"\"\n",
    "\n",
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(summery_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=summery_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "\n",
    "# Set the values of your computer vision endpoint and computer vision key as environment variables:\n",
    "try:\n",
    "    endpoint = ocr_endpoint\n",
    "    key = ocr_key\n",
    "except KeyError:\n",
    "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()\n",
    "\n",
    "def image_OCR(input_image):\n",
    "    read_text = []\n",
    "    # Create an Image Analysis client\n",
    "    client = ImageAnalysisClient(\n",
    "        endpoint=ocr_endpoint,\n",
    "        credential=AzureKeyCredential(ocr_key)\n",
    "    )\n",
    "\n",
    "    visual_features=[\n",
    "        VisualFeatures.READ\n",
    "        ]\n",
    "\n",
    "    if not \"https://\" in input_image or not \"http://\" in input_image:\n",
    "    # Load image to analyze into a 'bytes' object\n",
    "        with open(input_image, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "\n",
    "            # Get a caption for the image. This will be a synchronously (blocking) call. / ìš”ì²­í•œê±° ì‘ë‹µë°›ê¸°\n",
    "            result = client.analyze(\n",
    "                image_data=image_data,\n",
    "                visual_features=visual_features,\n",
    "                gender_neutral_caption=True,  # Optional (default is False)\n",
    "            )\n",
    "    else:\n",
    "        # Get a caption for the image. This will be a synchronously (blocking) call. / ìš”ì²­í•œê±° ì‘ë‹µë°›ê¸°\n",
    "        result = client.analyze_from_url(\n",
    "            image_url=input_image,\n",
    "            visual_features=visual_features,\n",
    "            gender_neutral_caption=True,  # Optional (default is False)\n",
    "        )\n",
    "\n",
    "    # Print text (OCR) analysis results to the console\n",
    "    # print(\" Read:\")\n",
    "    if result.read is not None:\n",
    "        for line in result.read.blocks[0].lines:\n",
    "            # print(line.text)\n",
    "            read_text.append(line.text)\n",
    "        return \"\".join(read_text)\n",
    "\n",
    "    from azure.ai.textanalytics import (\n",
    "        ExtractiveSummaryAction,\n",
    "    ) \n",
    "\n",
    "    document = [\n",
    "        \"\".join(read_text)\n",
    "    ]\n",
    "\n",
    "    poller_1 = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[\n",
    "            ExtractiveSummaryAction(max_sentence_count=4)\n",
    "        ],\n",
    "        language=\"ko\" # í•œêµ­ì–´\n",
    "    )\n",
    "\n",
    "    # poller_2 = client.begin_analyze_actions(\n",
    "    #     document,\n",
    "    #     actions=[\n",
    "    #         AbstractiveSummaryAction()\n",
    "    #     ],\n",
    "    #     language=\"ko\" # í•œêµ­ì–´\n",
    "    # )\n",
    "\n",
    "    document_results_1 = poller_1.result()\n",
    "\n",
    "    for result in document_results_1:\n",
    "        extract_summary_result = result[0]  # first document, first result\n",
    "        if extract_summary_result.is_error:\n",
    "            return \"...Is an error with code '{}' and message '{}'\".format(\n",
    "                extract_summary_result.code, extract_summary_result.message\n",
    "            )\n",
    "        else:\n",
    "            sentence_text_1 = \" \".join([sentence.text for sentence in extract_summary_result.sentences])\n",
    "            \n",
    "\n",
    "    # document_results_2 = poller_2.result()\n",
    "    \n",
    "    # for result in document_results_2:\n",
    "    #     extract_summary_result = result[0]  # first document, first result\n",
    "    #     if extract_summary_result.is_error:\n",
    "    #         print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "    #             extract_summary_result.code, extract_summary_result.message\n",
    "    #         ))\n",
    "    #     else:\n",
    "    #         print(\"Summary Abstractive: \\n{}\".format(\n",
    "    #             \" \".join([sentence.text for sentence in extract_summary_result.summaries]))\n",
    "    #         )\n",
    "\n",
    "    # This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription, region=region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "    # The neural multilingual voice can speak different languages based on the input text.\n",
    "    # ìŒì„± ì „í™˜ì„ ì›í•˜ë©´ ë§í¬ì—ì„œ í™•ì¸ í›„ ë³€ê²½ / https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#prebuilt-neural-voices\n",
    "    speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n",
    "\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # Get text from the console and synthesize to the default speaker.\n",
    "    # print(\"Enter some text that you want to speak >\")\n",
    "    text = sentence_text_1\n",
    "\n",
    "    speech_synthesizer.speak_text_async(text).get()\n",
    "       \n",
    "\n",
    "    return speech_synthesizer\n",
    "\n",
    "image_OCR(\"../Azure AI Vision/images/IMG_4692.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: on_underlying_io_bytes_received: Close frame received\n",
      "Info: on_underlying_io_bytes_received: closing underlying io.\n",
      "Info: on_underlying_io_close_complete: uws_state: 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gradio/blocks.py\", line 2103, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gradio/blocks.py\", line 1650, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gradio/utils.py\", line 890, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/sh/pq4glsrs3xq2v8ymsrw74mrr0000gn/T/ipykernel_87350/1843283396.py\", line 45, in image_OCR\n",
      "    result = image_client.analyze(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/core/tracing/decorator.py\", line 105, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/ai/vision/imageanalysis/_patch.py\", line 141, in analyze\n",
      "    return ImageAnalysisClientOperationsMixin._analyze_from_image_data(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/core/tracing/decorator.py\", line 105, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/ai/vision/imageanalysis/_operations/_operations.py\", line 333, in _analyze_from_image_data\n",
      "    map_error(status_code=response.status_code, response=response, error_map=error_map)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/core/exceptions.py\", line 163, in map_error\n",
      "    raise error\n",
      "azure.core.exceptions.ClientAuthenticationError: (401) Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.\n",
      "Code: 401\n",
      "Message: Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import gradio as gr\n",
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "# Azure AI services ì—”ë“œí¬ì¸íŠ¸ í‚¤ê°’í•„ìš”í•¨\n",
    "ocr_endpoint = ''\n",
    "ocr_key = ''\n",
    "\n",
    "# Language Service ì—”ë“œí¬ì¸íŠ¸ í‚¤ê°’\n",
    "summery_key = \"\"\n",
    "summery_endpoint = \"\"\n",
    "\n",
    "# AI Speech í‚¤ ì§€ì—­ \n",
    "subscription = \"\"\n",
    "region = \"\"\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "# Authenticate the client using your key and endpoint \n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(summery_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=summery_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "def image_OCR(input_image):\n",
    "    read_text = []\n",
    "\n",
    "    # OCR í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "    image_client = ImageAnalysisClient(\n",
    "        endpoint=ocr_endpoint,\n",
    "        credential=AzureKeyCredential(ocr_key)\n",
    "    )\n",
    "\n",
    "    visual_features = [VisualFeatures.READ]\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì½ê¸°\n",
    "    if not \"https://\" in input_image or not \"http://\" in input_image:\n",
    "        with open(input_image, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "            result = image_client.analyze(\n",
    "                image_data=image_data,\n",
    "                visual_features=visual_features,\n",
    "                gender_neutral_caption=True\n",
    "            )\n",
    "    else:\n",
    "        result = image_client.analyze_from_url(\n",
    "            image_url=input_image,\n",
    "            visual_features=visual_features,\n",
    "            gender_neutral_caption=True\n",
    "        )\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    if result.read is not None:\n",
    "        for line in result.read.blocks[0].lines:\n",
    "            read_text.append(line.text)\n",
    "\n",
    "    document = [\"\".join(read_text)]\n",
    "\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # ìš”ì•½ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "    from azure.ai.textanalytics import ExtractiveSummaryAction\n",
    "    client = authenticate_client()\n",
    "    poller = client.begin_analyze_actions(\n",
    "        document,\n",
    "        actions=[ExtractiveSummaryAction(max_sentence_count=4)],\n",
    "        language=\"ko\"\n",
    "    )\n",
    "    results = poller.result()\n",
    "\n",
    "    for result in results:\n",
    "        summary_result = result[0]\n",
    "        if summary_result.is_error:\n",
    "            return \"...Is an error with code '{}' and message '{}'\".format(\n",
    "                summary_result.code, summary_result.message\n",
    "            )\n",
    "        else:\n",
    "            summary_text = \" \".join([sentence.text for sentence in summary_result.sentences])\n",
    "\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # ìŒì„± í•©ì„±\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription, region=region)\n",
    "    speech_config.speech_synthesis_voice_name = 'en-US-AvaMultilingualNeural'\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmpfile:\n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(filename=tmpfile.name)\n",
    "        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "        synthesizer.speak_text_async(summary_text).get()\n",
    "        audio_path = tmpfile.name\n",
    "\n",
    "    return summary_text, audio_path\n",
    "\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "\n",
    "# ê·¸ë¼ë””ì˜¤ êµ¬í˜„\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ğŸ“„ ì´ë¯¸ì§€ ìš”ì•½ ë° ìŒì„± ì¶œë ¥ ì‹œìŠ¤í…œ\")\n",
    "    gr.Markdown(\"ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•˜ê³ , ìŒì„±ìœ¼ë¡œ ì½ì–´ì¤ë‹ˆë‹¤.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        image_input = gr.Image(type=\"filepath\", label=\"ì´ë¯¸ì§€ ì—…ë¡œë“œ\")\n",
    "    \n",
    "    summary_output = gr.Textbox(label=\"ìš”ì•½ ê²°ê³¼\")\n",
    "    audio_output = gr.Audio(label=\"ìŒì„± ê²°ê³¼\", type=\"filepath\")\n",
    "\n",
    "    run_button = gr.Button(\"ìš”ì•½ ë° ìŒì„± ì¶œë ¥ ì‹¤í–‰\")\n",
    "\n",
    "    run_button.click(fn=image_OCR, inputs=[image_input], outputs=[summary_output, audio_output])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
